{"updateTime":"2024-11-03 02:24:12","data":[{"username":"DefTruth","name":"DefTruth","type":"user","url":"https://github.com/DefTruth","avatar":"https://avatars.githubusercontent.com/u/31974251?s=96&v=4","repo":{"name":"CUDA-Learn-Notes","description":"ðŸŽ‰ Modern CUDA Learn Notes with PyTorch: CUDA Cores, Tensor Cores, fp32/tf32, fp16/bf16, fp8/int8, flash_attn, rope, sgemm, hgemm, sgemv, â€¦","url":"https://github.com/DefTruth/CUDA-Learn-Notes"}},{"username":"brucefan1983","name":"Zheyong Fan","type":"user","url":"https://github.com/brucefan1983","avatar":"https://avatars.githubusercontent.com/u/24891193?s=96&v=4","repo":{"name":"CUDA-Programming","description":"Sample codes for my CUDA programming book","url":"https://github.com/brucefan1983/CUDA-Programming"}},{"username":"BBuf","name":"Xiaoyu Zhang","type":"user","url":"https://github.com/BBuf","avatar":"https://avatars.githubusercontent.com/u/35585791?s=96&v=4","repo":{"name":"how-to-optim-algorithm-in-cuda","description":"how to optimize some algorithm in cuda.","url":"https://github.com/BBuf/how-to-optim-algorithm-in-cuda"}},{"username":"siboehm","name":"Simon Boehm","type":"user","url":"https://github.com/siboehm","avatar":"https://avatars.githubusercontent.com/u/14908678?s=96&v=4","repo":{"name":"SGEMM_CUDA","description":"Fast CUDA matrix multiplication from scratch","url":"https://github.com/siboehm/SGEMM_CUDA"}}]}
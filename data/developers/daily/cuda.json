{"updateTime":"2025-02-17 02:24:28","data":[{"username":"DefTruth","name":"DefTruth        ","type":"user","url":"https://github.com/DefTruth","avatar":"https://avatars.githubusercontent.com/u/31974251?s=96&v=4","repo":{"name":"CUDA-Learn-Notes","description":"ğŸ“š200+ Tensor/CUDA Cores Kernels, âš¡ï¸flash-attn-mma, âš¡ï¸hgemm with WMMA, MMA and CuTe (98%~100% TFLOPS of cuBLAS/FA2 ğŸ‰ğŸ‰).","url":"https://github.com/DefTruth/CUDA-Learn-Notes"}},{"username":"Isotr0py","name":"Isotr0py        ","type":"user","url":"https://github.com/Isotr0py","avatar":"https://avatars.githubusercontent.com/u/41363108?s=96&v=4","repo":{"name":"ggml-libtorch","description":"","url":"https://github.com/Isotr0py/ggml-libtorch"}},{"username":"siboehm","name":"Simon Boehm        ","type":"user","url":"https://github.com/siboehm","avatar":"https://avatars.githubusercontent.com/u/14908678?s=96&v=4","repo":{"name":"SGEMM_CUDA","description":"Fast CUDA matrix multiplication from scratch","url":"https://github.com/siboehm/SGEMM_CUDA"}}]}
{"updateTime":"2024-06-06 02:22:01","data":[{"full_name":"","description":"CUDA Library Samples","currentPeriodStars":110,"language":"Cuda","languageColor":"#3A4E3A","stargazers_count":1342,"forks_count":0,"owner":{"avatar_url":"https://avatars.githubusercontent.com/u/50021634?s=40&v=4","login":"mnicely"},"buildBy":[{"avatar_url":"https://avatars.githubusercontent.com/u/50021634?s=40&v=4","login":"mnicely"},{"avatar_url":"https://avatars.githubusercontent.com/u/50413820?s=40&v=4","login":"fbusato"},{"avatar_url":"https://avatars.githubusercontent.com/u/5178240?s=40&v=4","login":"springer13"},{"avatar_url":"https://avatars.githubusercontent.com/u/20576829?s=40&v=4","login":"almogsegal"},{"avatar_url":"https://avatars.githubusercontent.com/u/1907101?s=40&v=4","login":"mrogowski"}]},{"full_name":"","description":"A massively parallel, optimal functional runtime in Rust","currentPeriodStars":2996,"language":"Cuda","languageColor":"#3A4E3A","stargazers_count":10108,"forks_count":0,"owner":{"avatar_url":"https://avatars.githubusercontent.com/u/13090166?s=40&v=4","login":"VictorTaelin"},"buildBy":[{"avatar_url":"https://avatars.githubusercontent.com/u/13090166?s=40&v=4","login":"VictorTaelin"},{"avatar_url":"https://avatars.githubusercontent.com/u/5505315?s=40&v=4","login":"enricozb"},{"avatar_url":"https://avatars.githubusercontent.com/u/53550620?s=40&v=4","login":"kings177"},{"avatar_url":"https://avatars.githubusercontent.com/u/44031566?s=40&v=4","login":"tjjfvi"},{"avatar_url":"https://avatars.githubusercontent.com/u/4893601?s=40&v=4","login":"developedby"}]},{"full_name":"","description":"NCCL Tests","currentPeriodStars":39,"language":"Cuda","languageColor":"#3A4E3A","stargazers_count":706,"forks_count":0,"owner":{"avatar_url":"https://avatars.githubusercontent.com/u/2538330?s=40&v=4","login":"AddyLaddy"},"buildBy":[{"avatar_url":"https://avatars.githubusercontent.com/u/2538330?s=40&v=4","login":"AddyLaddy"},{"avatar_url":"https://avatars.githubusercontent.com/u/12857445?s=40&v=4","login":"sjeaugey"},{"avatar_url":"https://avatars.githubusercontent.com/u/687269?s=40&v=4","login":"lukeyeager"},{"avatar_url":"https://avatars.githubusercontent.com/u/2293859?s=40&v=4","login":"jbachan"},{"avatar_url":"https://avatars.githubusercontent.com/u/6690627?s=40&v=4","login":"jithinjosepkl"}]},{"full_name":"","description":"","currentPeriodStars":0,"stargazers_count":0,"forks_count":0,"owner":{},"buildBy":[]},{"full_name":"","description":"An efficient GPU support for LLM inference with x-bit quantization (e.g. FP6,FP5).","currentPeriodStars":59,"language":"Cuda","languageColor":"#3A4E3A","stargazers_count":137,"forks_count":0,"owner":{"avatar_url":"https://avatars.githubusercontent.com/u/21361095?s=40&v=4","login":"Summer-Summer"},"buildBy":[{"avatar_url":"https://avatars.githubusercontent.com/u/21361095?s=40&v=4","login":"Summer-Summer"},{"avatar_url":"https://avatars.githubusercontent.com/u/9893876?s=40&v=4","login":"JamesTheZ"}]},{"full_name":"","description":"[MICRO'23, MLSys'22] TorchSparse: Efficient Training and Inference Framework for Sparse Convolution on GPUs.","currentPeriodStars":17,"language":"Cuda","languageColor":"#3A4E3A","stargazers_count":1130,"forks_count":0,"owner":{"avatar_url":"https://avatars.githubusercontent.com/u/30133450?s=40&v=4","login":"kentang-mit"},"buildBy":[{"avatar_url":"https://avatars.githubusercontent.com/u/30133450?s=40&v=4","login":"kentang-mit"},{"avatar_url":"https://avatars.githubusercontent.com/u/2824685?s=40&v=4","login":"CCInc"},{"avatar_url":"https://avatars.githubusercontent.com/u/61508922?s=40&v=4","login":"ys-2020"},{"avatar_url":"https://avatars.githubusercontent.com/u/11742991?s=40&v=4","login":"sandeepnmenon"},{"avatar_url":"https://avatars.githubusercontent.com/u/20851944?s=40&v=4","login":"Xiuyu-Li"}]},{"full_name":"","description":"Sample codes for my CUDA programming book","currentPeriodStars":50,"language":"Cuda","languageColor":"#3A4E3A","stargazers_count":1401,"forks_count":0,"owner":{"avatar_url":"https://avatars.githubusercontent.com/u/24891193?s=40&v=4","login":"brucefan1983"},"buildBy":[{"avatar_url":"https://avatars.githubusercontent.com/u/24891193?s=40&v=4","login":"brucefan1983"},{"avatar_url":"https://avatars.githubusercontent.com/u/36254396?s=40&v=4","login":"YouQixiaowu"},{"avatar_url":"https://avatars.githubusercontent.com/u/19585240?s=40&v=4","login":"tomguluson92"}]},{"full_name":"","description":"cuVS - a library for vector search and clustering on the GPU","currentPeriodStars":25,"language":"Cuda","languageColor":"#3A4E3A","stargazers_count":111,"forks_count":0,"owner":{"avatar_url":"https://avatars.githubusercontent.com/u/1242464?s=40&v=4","login":"cjnolet"},"buildBy":[{"avatar_url":"https://avatars.githubusercontent.com/u/1242464?s=40&v=4","login":"cjnolet"},{"avatar_url":"https://avatars.githubusercontent.com/u/69536?s=40&v=4","login":"benfred"},{"avatar_url":"https://avatars.githubusercontent.com/u/3107146?s=40&v=4","login":"raydouglass"},{"avatar_url":"https://avatars.githubusercontent.com/u/156017155?s=40&v=4","login":"KyleFromNVIDIA"},{"avatar_url":"https://avatars.githubusercontent.com/u/178183?s=40&v=4","login":"trxcllnt"}]},{"full_name":"","description":"This is a series of GPU optimization topics. Here we will introduce how to optimize the CUDA kernel in detail. I will introduce several basic kernel optimizations, including: elementwise, reduce, sgemv, sgemm, etc. The performance of these kernels is basically at or near the theoretical limit.","currentPeriodStars":40,"language":"Cuda","languageColor":"#3A4E3A","stargazers_count":716,"forks_count":0,"owner":{"avatar_url":"https://avatars.githubusercontent.com/u/85323580?s=40&v=4","login":"Liu-xiandong"},"buildBy":[{"avatar_url":"https://avatars.githubusercontent.com/u/85323580?s=40&v=4","login":"Liu-xiandong"},{"avatar_url":"https://avatars.githubusercontent.com/u/63796752?s=40&v=4","login":"ZhangGe6"}]},{"full_name":"","description":"Causal depthwise conv1d in CUDA, with a PyTorch interface","currentPeriodStars":22,"language":"Cuda","languageColor":"#3A4E3A","stargazers_count":195,"forks_count":0,"owner":{"avatar_url":"https://avatars.githubusercontent.com/u/5616128?s=40&v=4","login":"tridao"},"buildBy":[{"avatar_url":"https://avatars.githubusercontent.com/u/5616128?s=40&v=4","login":"tridao"},{"avatar_url":"https://avatars.githubusercontent.com/u/9017200?s=40&v=4","login":"havietisov"},{"avatar_url":"https://avatars.githubusercontent.com/u/32878682?s=40&v=4","login":"IamShubhamGupto"},{"avatar_url":"https://avatars.githubusercontent.com/u/44860323?s=40&v=4","login":"Wongboo"}]},{"full_name":"","description":"CUDA accelerated rasterization of gaussian splatting","currentPeriodStars":67,"language":"Cuda","languageColor":"#3A4E3A","stargazers_count":916,"forks_count":0,"owner":{"avatar_url":"https://avatars.githubusercontent.com/u/5694811?s=40&v=4","login":"vye16"},"buildBy":[{"avatar_url":"https://avatars.githubusercontent.com/u/5694811?s=40&v=4","login":"vye16"},{"avatar_url":"https://avatars.githubusercontent.com/u/10151885?s=40&v=4","login":"liruilong940607"},{"avatar_url":"https://avatars.githubusercontent.com/u/30566358?s=40&v=4","login":"maturk"},{"avatar_url":"https://avatars.githubusercontent.com/u/15806475?s=40&v=4","login":"kerrj"},{"avatar_url":"https://avatars.githubusercontent.com/u/102644383?s=40&v=4","login":"Zhuoyang-Pan"}]},{"full_name":"","description":"cuGraph - RAPIDS Graph Analytics Library","currentPeriodStars":32,"language":"Cuda","languageColor":"#3A4E3A","stargazers_count":1607,"forks_count":0,"owner":{"avatar_url":"https://avatars.githubusercontent.com/u/34135411?s=40&v=4","login":"BradReesWork"},"buildBy":[{"avatar_url":"https://avatars.githubusercontent.com/u/34135411?s=40&v=4","login":"BradReesWork"},{"avatar_url":"https://avatars.githubusercontent.com/u/45606510?s=40&v=4","login":"afender"},{"avatar_url":"https://avatars.githubusercontent.com/u/45857425?s=40&v=4","login":"seunghwak"},{"avatar_url":"https://avatars.githubusercontent.com/u/45364586?s=40&v=4","login":"ChuckHastings"},{"avatar_url":"https://avatars.githubusercontent.com/u/41401566?s=40&v=4","login":"Iroy30"}]},{"full_name":"","description":"Distributed multigrid linear solver library on GPU","currentPeriodStars":9,"language":"Cuda","languageColor":"#3A4E3A","stargazers_count":456,"forks_count":0,"owner":{"avatar_url":"https://avatars.githubusercontent.com/u/9931059?s=40&v=4","login":"mattmartineau"},"buildBy":[{"avatar_url":"https://avatars.githubusercontent.com/u/9931059?s=40&v=4","login":"mattmartineau"},{"avatar_url":"https://avatars.githubusercontent.com/u/32493426?s=40&v=4","login":"marsaev"},{"avatar_url":"https://avatars.githubusercontent.com/u/65027571?s=40&v=4","login":"gonzalobg"},{"avatar_url":"https://avatars.githubusercontent.com/u/51991688?s=40&v=4","login":"mhrywniak"},{"avatar_url":"https://avatars.githubusercontent.com/u/971921?s=40&v=4","login":"ibaned"}]},{"full_name":"","description":"RAFT contains fundamental widely-used algorithms and primitives for machine learning and information retrieval. The algorithms are CUDA-accelerated and form building blocks for more easily writing high performance applications.","currentPeriodStars":29,"language":"Cuda","languageColor":"#3A4E3A","stargazers_count":640,"forks_count":0,"owner":{"avatar_url":"https://avatars.githubusercontent.com/u/1242464?s=40&v=4","login":"cjnolet"},"buildBy":[{"avatar_url":"https://avatars.githubusercontent.com/u/1242464?s=40&v=4","login":"cjnolet"},{"avatar_url":"https://avatars.githubusercontent.com/u/38199262?s=40&v=4","login":"GPUtester"},{"avatar_url":"https://avatars.githubusercontent.com/u/37386037?s=40&v=4","login":"aschaffer"},{"avatar_url":"https://avatars.githubusercontent.com/u/9253178?s=40&v=4","login":"achirkin"},{"avatar_url":"https://avatars.githubusercontent.com/u/14876585?s=40&v=4","login":"divyegala"}]},{"full_name":"","description":"","currentPeriodStars":0,"stargazers_count":0,"forks_count":0,"owner":{},"buildBy":[]}]}
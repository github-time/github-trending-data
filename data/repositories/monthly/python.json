{"updateTime":"2025-01-19 02:25:09","data":[{"full_name":"","description":"An LLM-powered knowledge curation system that researches a topic and generates a full-length report with citations.","currentPeriodStars":6706,"language":"Python","languageColor":"#3572A5","stargazers_count":20364,"forks_count":0,"owner":{"avatar_url":"https://avatars.githubusercontent.com/u/67158122?s=40&v=4","login":"shaoyijia"},"buildBy":[{"avatar_url":"https://avatars.githubusercontent.com/u/67158122?s=40&v=4","login":"shaoyijia"},{"avatar_url":"https://avatars.githubusercontent.com/u/51142637?s=40&v=4","login":"Yucheng-Jiang"},{"avatar_url":"https://avatars.githubusercontent.com/u/35606009?s=40&v=4","login":"zenith110"},{"avatar_url":"https://avatars.githubusercontent.com/u/96901711?s=40&v=4","login":"AMMAS1"},{"avatar_url":"https://avatars.githubusercontent.com/u/24313466?s=40&v=4","login":"evidencebp"}]},{"full_name":"","description":"Your AI second brain. Self-hostable. Get answers from the web or your docs. Build custom agents, schedule automations, do deep research. Turn any online or local LLM into your personal, autonomous AI (gpt, claude, gemini, llama, qwen, mistral). Get started - free.","currentPeriodStars":7699,"language":"Python","languageColor":"#3572A5","stargazers_count":24873,"forks_count":0,"owner":{"avatar_url":"https://avatars.githubusercontent.com/u/6413477?s=40&v=4","login":"debanjum"},"buildBy":[{"avatar_url":"https://avatars.githubusercontent.com/u/6413477?s=40&v=4","login":"debanjum"},{"avatar_url":"https://avatars.githubusercontent.com/u/65192171?s=40&v=4","login":"sabaimran"},{"avatar_url":"https://avatars.githubusercontent.com/u/62105787?s=40&v=4","login":"MythicalCow"},{"avatar_url":"https://avatars.githubusercontent.com/u/486336?s=40&v=4","login":"aam-at"},{"avatar_url":"https://avatars.githubusercontent.com/u/42291955?s=40&v=4","login":"hjamet"}]},{"full_name":"","description":"Collection of awesome LLM apps with AI Agents and RAG using OpenAI, Anthropic, Gemini and opensource models.","currentPeriodStars":5966,"language":"Python","languageColor":"#3572A5","stargazers_count":12784,"forks_count":0,"owner":{"avatar_url":"https://avatars.githubusercontent.com/u/31396011?s=40&v=4","login":"Shubhamsaboo"},"buildBy":[{"avatar_url":"https://avatars.githubusercontent.com/u/31396011?s=40&v=4","login":"Shubhamsaboo"},{"avatar_url":"https://avatars.githubusercontent.com/u/124294538?s=40&v=4","login":"Madhuvod"},{"avatar_url":"https://avatars.githubusercontent.com/u/917273?s=40&v=4","login":"Vadiml1024"},{"avatar_url":"https://avatars.githubusercontent.com/u/145006093?s=40&v=4","login":"gargigupta97"},{"avatar_url":"https://avatars.githubusercontent.com/u/261698?s=40&v=4","login":"ideal"}]},{"full_name":"","description":"ğŸš€ğŸ¤– Crawl4AI: Open-source LLM Friendly Web Crawler & Scraper","currentPeriodStars":7083,"language":"Python","languageColor":"#3572A5","stargazers_count":25746,"forks_count":0,"owner":{"avatar_url":"https://avatars.githubusercontent.com/u/12494079?s=40&v=4","login":"unclecode"},"buildBy":[{"avatar_url":"https://avatars.githubusercontent.com/u/12494079?s=40&v=4","login":"unclecode"},{"avatar_url":"https://avatars.githubusercontent.com/u/17730156?s=40&v=4","login":"bizrockman"},{"avatar_url":"https://avatars.githubusercontent.com/u/62844803?s=40&v=4","login":"datehoer"},{"avatar_url":"https://avatars.githubusercontent.com/u/15815124?s=40&v=4","login":"aravindkarnam"},{"avatar_url":"https://avatars.githubusercontent.com/u/29380294?s=40&v=4","login":"mjvankampen"}]},{"full_name":"","description":"KAG is a logical form-guided reasoning and retrieval framework based on OpenSPG engine and LLMs. It is used to build logical reasoning and factual Q&A solutions for professional domain knowledge bases. It can effectively overcome the shortcomings of the traditional RAG vector similarity calculation model.","currentPeriodStars":3519,"language":"Python","languageColor":"#3572A5","stargazers_count":4356,"forks_count":0,"owner":{"avatar_url":"https://avatars.githubusercontent.com/u/30171612?s=40&v=4","login":"northmachine"},"buildBy":[{"avatar_url":"https://avatars.githubusercontent.com/u/30171612?s=40&v=4","login":"northmachine"},{"avatar_url":"https://avatars.githubusercontent.com/u/5087599?s=40&v=4","login":"xionghuaidong"},{"avatar_url":"https://avatars.githubusercontent.com/u/15404227?s=40&v=4","login":"caszkgui"},{"avatar_url":"https://avatars.githubusercontent.com/u/152354526?s=40&v=4","login":"zhuzhongshu123"},{"avatar_url":"https://avatars.githubusercontent.com/u/19925690?s=40&v=4","login":"andylau-55"}]},{"full_name":"","description":"NVIDIA Ingest is an early access set of microservices for parsing hundreds of thousands of complex, messy unstructured PDFs and other enterprise documents into metadata and text to embed into retrieval systems.","currentPeriodStars":1967,"language":"Python","languageColor":"#3572A5","stargazers_count":2188,"forks_count":0,"owner":{"avatar_url":"https://avatars.githubusercontent.com/u/2127235?s=40&v=4","login":"jdye64"},"buildBy":[{"avatar_url":"https://avatars.githubusercontent.com/u/2127235?s=40&v=4","login":"jdye64"},{"avatar_url":"https://avatars.githubusercontent.com/u/5256797?s=40&v=4","login":"drobison00"},{"avatar_url":"https://avatars.githubusercontent.com/u/109497216?s=40&v=4","login":"edknv"},{"avatar_url":"https://avatars.githubusercontent.com/u/1692914?s=40&v=4","login":"randerzander"},{"avatar_url":"https://avatars.githubusercontent.com/u/37191411?s=40&v=4","login":"jperez999"}]},{"full_name":"","description":"A generative world for general-purpose robotics & embodied AI learning.","currentPeriodStars":22545,"language":"Python","languageColor":"#3572A5","stargazers_count":22965,"forks_count":0,"owner":{"avatar_url":"https://avatars.githubusercontent.com/u/19647225?s=40&v=4","login":"zhouxian"},"buildBy":[{"avatar_url":"https://avatars.githubusercontent.com/u/19647225?s=40&v=4","login":"zhouxian"},{"avatar_url":"https://avatars.githubusercontent.com/u/49262224?s=40&v=4","login":"YilingQiao"},{"avatar_url":"https://avatars.githubusercontent.com/u/22212062?s=40&v=4","login":"zswang666"},{"avatar_url":"https://avatars.githubusercontent.com/u/13469640?s=40&v=4","login":"zhenjia-xu"},{"avatar_url":"https://avatars.githubusercontent.com/u/39104615?s=40&v=4","login":"Kashu7100"}]},{"full_name":"","description":"MiniCPM-o 2.6: A GPT-4o Level MLLM for Vision, Speech and Multimodal Live Streaming on Your Phone","currentPeriodStars":1890,"language":"Python","languageColor":"#3572A5","stargazers_count":15546,"forks_count":0,"owner":{"avatar_url":"https://avatars.githubusercontent.com/u/28106858?s=40&v=4","login":"yiranyyu"},"buildBy":[{"avatar_url":"https://avatars.githubusercontent.com/u/28106858?s=40&v=4","login":"yiranyyu"},{"avatar_url":"https://avatars.githubusercontent.com/u/5380770?s=40&v=4","login":"iceflame89"},{"avatar_url":"https://avatars.githubusercontent.com/u/19372848?s=40&v=4","login":"yaoyuanTHU"},{"avatar_url":"https://avatars.githubusercontent.com/u/47373076?s=40&v=4","login":"LDLINGLINGLING"},{"avatar_url":"https://avatars.githubusercontent.com/u/157115220?s=40&v=4","login":"tc-mb"}]},{"full_name":"","description":"ğŸš€ğŸš€ ã€Œå¤§æ¨¡å‹ã€3å°æ—¶å®Œå…¨ä»0è®­ç»ƒ26Mçš„å°å‚æ•°GPTï¼ğŸŒ Train a 26M-parameter GPT from scratch in just 3 hours!","currentPeriodStars":2035,"language":"Python","languageColor":"#3572A5","stargazers_count":5038,"forks_count":0,"owner":{"avatar_url":"https://avatars.githubusercontent.com/u/62287848?s=40&v=4","login":"jingyaogong"},"buildBy":[{"avatar_url":"https://avatars.githubusercontent.com/u/62287848?s=40&v=4","login":"jingyaogong"},{"avatar_url":"https://avatars.githubusercontent.com/u/124225682?s=40&v=4","login":"iomgaa-ycz"},{"avatar_url":"https://avatars.githubusercontent.com/u/2813798?s=40&v=4","login":"chuanzhubin"},{"avatar_url":"https://avatars.githubusercontent.com/u/93832089?s=40&v=4","login":"MuWinds"}]},{"full_name":"","description":"Learn how to design large-scale systems. Prep for the system design interview. Includes Anki flashcards.","currentPeriodStars":7193,"language":"Python","languageColor":"#3572A5","stargazers_count":286247,"forks_count":0,"owner":{"avatar_url":"https://avatars.githubusercontent.com/u/5458997?s=40&v=4","login":"donnemartin"},"buildBy":[{"avatar_url":"https://avatars.githubusercontent.com/u/5458997?s=40&v=4","login":"donnemartin"},{"avatar_url":"https://avatars.githubusercontent.com/u/3709715?s=40&v=4","login":"cclauss"},{"avatar_url":"https://avatars.githubusercontent.com/u/171818?s=40&v=4","login":"satob"},{"avatar_url":"https://avatars.githubusercontent.com/u/7440735?s=40&v=4","login":"fluency03"},{"avatar_url":"https://avatars.githubusercontent.com/u/8622362?s=40&v=4","login":"linhe0x0"}]},{"full_name":"","description":"ğŸ™Œ OpenHands: Code Less, Make More","currentPeriodStars":5251,"language":"Python","languageColor":"#3572A5","stargazers_count":43817,"forks_count":0,"owner":{"avatar_url":"https://avatars.githubusercontent.com/in/29110?s=40&v=4","login":"dependabot"},"buildBy":[{"avatar_url":"https://avatars.githubusercontent.com/in/29110?s=40&v=4","login":"dependabot"},{"avatar_url":"https://avatars.githubusercontent.com/u/7611973?s=40&v=4","login":"rbren"},{"avatar_url":"https://avatars.githubusercontent.com/u/38853559?s=40&v=4","login":"xingyaoww"},{"avatar_url":"https://avatars.githubusercontent.com/u/6080905?s=40&v=4","login":"enyst"},{"avatar_url":"https://avatars.githubusercontent.com/u/83104063?s=40&v=4","login":"amanape"}]},{"full_name":"","description":"A fast multimodal LLM for real-time voice","currentPeriodStars":1191,"language":"Python","languageColor":"#3572A5","stargazers_count":2852,"forks_count":0,"owner":{"avatar_url":"https://avatars.githubusercontent.com/u/1821693?s=40&v=4","login":"juberti"},"buildBy":[{"avatar_url":"https://avatars.githubusercontent.com/u/1821693?s=40&v=4","login":"juberti"},{"avatar_url":"https://avatars.githubusercontent.com/u/5062458?s=40&v=4","login":"farzadab"},{"avatar_url":"https://avatars.githubusercontent.com/u/11863813?s=40&v=4","login":"zqhuang211"},{"avatar_url":"https://avatars.githubusercontent.com/u/8979025?s=40&v=4","login":"liPatrick"},{"avatar_url":"https://avatars.githubusercontent.com/u/130235?s=40&v=4","login":"zkoch"}]},{"full_name":"","description":"Framework for orchestrating role-playing, autonomous AI agents. By fostering collaborative intelligence, CrewAI empowers agents to work together seamlessly, tackling complex tasks.","currentPeriodStars":2367,"language":"Python","languageColor":"#3572A5","stargazers_count":24906,"forks_count":0,"owner":{"avatar_url":"https://avatars.githubusercontent.com/u/667063?s=40&v=4","login":"joaomdmoura"},"buildBy":[{"avatar_url":"https://avatars.githubusercontent.com/u/667063?s=40&v=4","login":"joaomdmoura"},{"avatar_url":"https://avatars.githubusercontent.com/u/109994880?s=40&v=4","login":"bhancockio"},{"avatar_url":"https://avatars.githubusercontent.com/u/25188076?s=40&v=4","login":"pythonbyte"},{"avatar_url":"https://avatars.githubusercontent.com/u/63378463?s=40&v=4","login":"lorenzejay"},{"avatar_url":"https://avatars.githubusercontent.com/u/84775494?s=40&v=4","login":"theCyberTech"}]},{"full_name":"","description":"PDF scientific paper translation with preserved formats - åŸºäº AI å®Œæ•´ä¿ç•™æ’ç‰ˆçš„ PDF æ–‡æ¡£å…¨æ–‡åŒè¯­ç¿»è¯‘ï¼Œæ”¯æŒ Google/DeepL/Ollama/OpenAI ç­‰æœåŠ¡ï¼Œæä¾› CLI/GUI/Docker","currentPeriodStars":6599,"language":"Python","languageColor":"#3572A5","stargazers_count":15503,"forks_count":0,"owner":{"avatar_url":"https://avatars.githubusercontent.com/u/21212051?s=40&v=4","login":"Byaidu"},"buildBy":[{"avatar_url":"https://avatars.githubusercontent.com/u/21212051?s=40&v=4","login":"Byaidu"},{"avatar_url":"https://avatars.githubusercontent.com/u/11225092?s=40&v=4","login":"reycn"},{"avatar_url":"https://avatars.githubusercontent.com/u/42131198?s=40&v=4","login":"hellofinch"},{"avatar_url":"https://avatars.githubusercontent.com/u/8493196?s=40&v=4","login":"awwaawwa"},{"avatar_url":"https://avatars.githubusercontent.com/u/58414341?s=40&v=4","login":"tastelikefeet"}]},{"full_name":"","description":"SGLang is a fast serving framework for large language models and vision language models.","currentPeriodStars":842,"language":"Python","languageColor":"#3572A5","stargazers_count":7387,"forks_count":0,"owner":{"avatar_url":"https://avatars.githubusercontent.com/u/15100009?s=40&v=4","login":"merrymercy"},"buildBy":[{"avatar_url":"https://avatars.githubusercontent.com/u/15100009?s=40&v=4","login":"merrymercy"},{"avatar_url":"https://avatars.githubusercontent.com/u/46627482?s=40&v=4","login":"zhyncs"},{"avatar_url":"https://avatars.githubusercontent.com/u/9302255?s=40&v=4","login":"Ying1123"},{"avatar_url":"https://avatars.githubusercontent.com/u/95566987?s=40&v=4","login":"hnyls2002"},{"avatar_url":"https://avatars.githubusercontent.com/u/24364830?s=40&v=4","login":"ByronHsu"}]},{"full_name":"","description":"AutoGPT is the vision of accessible AI for everyone, to use and to build on. Our mission is to provide the tools, so that you can focus on what matters.","currentPeriodStars":1733,"language":"Python","languageColor":"#3572A5","stargazers_count":170613,"forks_count":0,"owner":{"avatar_url":"https://avatars.githubusercontent.com/u/133978099?s=40&v=4","login":"Auto-GPT-Bot"},"buildBy":[{"avatar_url":"https://avatars.githubusercontent.com/u/133978099?s=40&v=4","login":"Auto-GPT-Bot"},{"avatar_url":"https://avatars.githubusercontent.com/u/12185583?s=40&v=4","login":"Pwuts"},{"avatar_url":"https://avatars.githubusercontent.com/u/9652976?s=40&v=4","login":"waynehamadi"},{"avatar_url":"https://avatars.githubusercontent.com/u/22963551?s=40&v=4","login":"Torantulino"},{"avatar_url":"https://avatars.githubusercontent.com/u/10382233?s=40&v=4","login":"Swiftyos"}]},{"full_name":"","description":"åˆ©ç”¨AIå¤§æ¨¡å‹ï¼Œä¸€é”®ç”Ÿæˆé«˜æ¸…çŸ­è§†é¢‘ Generate short videos with one click using AI LLM.","currentPeriodStars":1554,"language":"Python","languageColor":"#3572A5","stargazers_count":20512,"forks_count":0,"owner":{"avatar_url":"https://avatars.githubusercontent.com/u/4928832?s=40&v=4","login":"harry0703"},"buildBy":[{"avatar_url":"https://avatars.githubusercontent.com/u/4928832?s=40&v=4","login":"harry0703"},{"avatar_url":"https://avatars.githubusercontent.com/u/95077259?s=40&v=4","login":"yyhhyyyyyy"},{"avatar_url":"https://avatars.githubusercontent.com/u/96235876?s=40&v=4","login":"vuisme"},{"avatar_url":"https://avatars.githubusercontent.com/u/13794286?s=40&v=4","login":"KevinZhang19870314"},{"avatar_url":"https://avatars.githubusercontent.com/u/100217654?s=40&v=4","login":"KPCOFGS"}]},{"full_name":"","description":"Python APIs for web automation, testing, and bypassing bot-detection.","currentPeriodStars":3579,"language":"Python","languageColor":"#3572A5","stargazers_count":9145,"forks_count":0,"owner":{"avatar_url":"https://avatars.githubusercontent.com/u/6788579?s=40&v=4","login":"mdmintz"},"buildBy":[{"avatar_url":"https://avatars.githubusercontent.com/u/6788579?s=40&v=4","login":"mdmintz"},{"avatar_url":"https://avatars.githubusercontent.com/u/10913529?s=40&v=4","login":"hiqqs"},{"avatar_url":"https://avatars.githubusercontent.com/u/5632761?s=40&v=4","login":"piotrkochan"},{"avatar_url":"https://avatars.githubusercontent.com/u/11387076?s=40&v=4","login":"surevs"},{"avatar_url":"https://avatars.githubusercontent.com/u/12161724?s=40&v=4","login":"stevemachacz"}]},{"full_name":"","description":"VILA is a family of state-of-the-art vision language models (VLMs) for diverse multimodal AI tasks across the edge, data center, and cloud.","currentPeriodStars":600,"language":"Python","languageColor":"#3572A5","stargazers_count":2768,"forks_count":0,"owner":{"avatar_url":"https://avatars.githubusercontent.com/u/91149044?s=40&v=4","login":"yaolug"},"buildBy":[{"avatar_url":"https://avatars.githubusercontent.com/u/91149044?s=40&v=4","login":"yaolug"},{"avatar_url":"https://avatars.githubusercontent.com/u/156256291?s=40&v=4","login":"Efficient-Large-Language-Model"},{"avatar_url":"https://avatars.githubusercontent.com/u/7783214?s=40&v=4","login":"Lyken17"},{"avatar_url":"https://avatars.githubusercontent.com/u/5782437?s=40&v=4","login":"zhijian-liu"},{"avatar_url":"https://avatars.githubusercontent.com/u/24690867?s=40&v=4","login":"yukang2017"}]}]}
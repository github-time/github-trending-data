{"updateTime":"2022-12-19 02:18:41","data":[{"full_name":"NVIDIA/cub","description":"Cooperative primitives for CUDA C++.","currentPeriodStars":0,"language":"Cuda","languageColor":"#3A4E3A","stargazers_count":1329,"forks_count":410,"owner":{"avatar_url":"https://avatars.githubusercontent.com/u/58744?s=40&v=4","login":"allisonvacanti"},"buildBy":[{"avatar_url":"https://avatars.githubusercontent.com/u/58744?s=40&v=4","login":"allisonvacanti"},{"avatar_url":"https://avatars.githubusercontent.com/u/9890394?s=40&v=4","login":"senior-zero"},{"avatar_url":"https://avatars.githubusercontent.com/u/1476032?s=40&v=4","login":"dumerrill"},{"avatar_url":"https://avatars.githubusercontent.com/u/398194?s=40&v=4","login":"brycelelbach"},{"avatar_url":"https://avatars.githubusercontent.com/u/3958403?s=40&v=4","login":"elstehle"}]},{"full_name":"Cjkkkk/CUDA_gemm","description":"A simple high performance CUDA GEMM implementation.","currentPeriodStars":1,"language":"Cuda","languageColor":"#3A4E3A","stargazers_count":74,"forks_count":15,"owner":{"avatar_url":"https://avatars.githubusercontent.com/u/25362393?s=40&v=4","login":"Cjkkkk"},"buildBy":[{"avatar_url":"https://avatars.githubusercontent.com/u/25362393?s=40&v=4","login":"Cjkkkk"},{"avatar_url":"https://avatars.githubusercontent.com/u/55869648?s=40&v=4","login":"zhacmsft"},{"avatar_url":"https://avatars.githubusercontent.com/u/50486294?s=40&v=4","login":"linbinskn"}]},{"full_name":"NVlabs/instant-ngp","description":"Instant neural graphics primitives: lightning fast NeRF and more","currentPeriodStars":9,"language":"Cuda","languageColor":"#3A4E3A","stargazers_count":10418,"forks_count":1237,"owner":{"avatar_url":"https://avatars.githubusercontent.com/u/4923655?s=40&v=4","login":"Tom94"},"buildBy":[{"avatar_url":"https://avatars.githubusercontent.com/u/4923655?s=40&v=4","login":"Tom94"},{"avatar_url":"https://avatars.githubusercontent.com/u/7601391?s=40&v=4","login":"FlorisE"},{"avatar_url":"https://avatars.githubusercontent.com/u/29726242?s=40&v=4","login":"jc211"},{"avatar_url":"https://avatars.githubusercontent.com/u/3280839?s=40&v=4","login":"JamesPerlman"},{"avatar_url":"https://avatars.githubusercontent.com/u/22482773?s=40&v=4","login":"koktavy"}]},{"full_name":"FLAMEGPU/FLAMEGPU2","description":"FLAME GPU 2 is a GPU accelerated agent based modelling framework for CUDA C++ and Python","currentPeriodStars":0,"language":"Cuda","languageColor":"#3A4E3A","stargazers_count":38,"forks_count":14,"owner":{"avatar_url":"https://avatars.githubusercontent.com/u/742154?s=40&v=4","login":"Robadob"},"buildBy":[{"avatar_url":"https://avatars.githubusercontent.com/u/742154?s=40&v=4","login":"Robadob"},{"avatar_url":"https://avatars.githubusercontent.com/u/628937?s=40&v=4","login":"ptheywood"},{"avatar_url":"https://avatars.githubusercontent.com/u/11078075?s=40&v=4","login":"mondus"},{"avatar_url":"https://avatars.githubusercontent.com/u/22101974?s=40&v=4","login":"mozhgan-kch"},{"avatar_url":"https://avatars.githubusercontent.com/u/6020572?s=40&v=4","login":"MILeach"}]},{"full_name":"leoxiaobin/deep-high-resolution-net.pytorch","description":"The project is an official implementation of our CVPR2019 paper \"Deep High-Resolution Representation Learning for Human Pose Estimation\"","currentPeriodStars":0,"language":"Cuda","languageColor":"#3A4E3A","stargazers_count":3935,"forks_count":886,"owner":{"avatar_url":"https://avatars.githubusercontent.com/u/5362509?s=40&v=4","login":"leoxiaobin"},"buildBy":[{"avatar_url":"https://avatars.githubusercontent.com/u/5362509?s=40&v=4","login":"leoxiaobin"},{"avatar_url":"https://avatars.githubusercontent.com/u/17076122?s=40&v=4","login":"welleast"},{"avatar_url":"https://avatars.githubusercontent.com/u/44516327?s=40&v=4","login":"CrystalSixone"},{"avatar_url":"https://avatars.githubusercontent.com/u/1326899?s=40&v=4","login":"alex9311"},{"avatar_url":"https://avatars.githubusercontent.com/u/2300329?s=40&v=4","login":"gachiemchiep"}]},{"full_name":"NVIDIA/TransformerEngine","description":"A library for accelerating Transformer models on NVIDIA GPUs, including using 8-bit floating point (FP8) precision on Hopper GPUs, to provide better performance with lower memory utilization in both training and inference.","currentPeriodStars":1,"language":"Cuda","languageColor":"#3A4E3A","stargazers_count":318,"forks_count":27,"owner":{"avatar_url":"https://avatars.githubusercontent.com/u/8398980?s=40&v=4","login":"ptrendx"},"buildBy":[{"avatar_url":"https://avatars.githubusercontent.com/u/8398980?s=40&v=4","login":"ptrendx"},{"avatar_url":"https://avatars.githubusercontent.com/u/36168853?s=40&v=4","login":"ksivaman"},{"avatar_url":"https://avatars.githubusercontent.com/u/4406448?s=40&v=4","login":"timmoon10"},{"avatar_url":"https://avatars.githubusercontent.com/u/883319?s=40&v=4","login":"seanprime7"},{"avatar_url":"https://avatars.githubusercontent.com/u/96238833?s=40&v=4","login":"nzmora-nvidia"}]}]}
{"updateTime":"2022-12-21 02:20:17","data":[{"full_name":"NVlabs/instant-ngp","description":"Instant neural graphics primitives: lightning fast NeRF and more","currentPeriodStars":11,"language":"Cuda","languageColor":"#3A4E3A","stargazers_count":10440,"forks_count":1237,"owner":{"avatar_url":"https://avatars.githubusercontent.com/u/4923655?s=40&v=4","login":"Tom94"},"buildBy":[{"avatar_url":"https://avatars.githubusercontent.com/u/4923655?s=40&v=4","login":"Tom94"},{"avatar_url":"https://avatars.githubusercontent.com/u/7601391?s=40&v=4","login":"FlorisE"},{"avatar_url":"https://avatars.githubusercontent.com/u/29726242?s=40&v=4","login":"jc211"},{"avatar_url":"https://avatars.githubusercontent.com/u/3280839?s=40&v=4","login":"JamesPerlman"},{"avatar_url":"https://avatars.githubusercontent.com/u/22482773?s=40&v=4","login":"koktavy"}]},{"full_name":"NVIDIA/TransformerEngine","description":"A library for accelerating Transformer models on NVIDIA GPUs, including using 8-bit floating point (FP8) precision on Hopper GPUs, to provide better performance with lower memory utilization in both training and inference.","currentPeriodStars":1,"language":"Cuda","languageColor":"#3A4E3A","stargazers_count":321,"forks_count":28,"owner":{"avatar_url":"https://avatars.githubusercontent.com/u/8398980?s=40&v=4","login":"ptrendx"},"buildBy":[{"avatar_url":"https://avatars.githubusercontent.com/u/8398980?s=40&v=4","login":"ptrendx"},{"avatar_url":"https://avatars.githubusercontent.com/u/36168853?s=40&v=4","login":"ksivaman"},{"avatar_url":"https://avatars.githubusercontent.com/u/4406448?s=40&v=4","login":"timmoon10"},{"avatar_url":"https://avatars.githubusercontent.com/u/883319?s=40&v=4","login":"seanprime7"},{"avatar_url":"https://avatars.githubusercontent.com/u/96238833?s=40&v=4","login":"nzmora-nvidia"}]},{"full_name":"NVIDIA/CUDALibrarySamples","description":"CUDA Library Samples","currentPeriodStars":2,"language":"Cuda","languageColor":"#3A4E3A","stargazers_count":581,"forks_count":175,"owner":{"avatar_url":"https://avatars.githubusercontent.com/u/50021634?s=40&v=4","login":"mnicely"},"buildBy":[{"avatar_url":"https://avatars.githubusercontent.com/u/50021634?s=40&v=4","login":"mnicely"},{"avatar_url":"https://avatars.githubusercontent.com/u/50413820?s=40&v=4","login":"fbusato"},{"avatar_url":"https://avatars.githubusercontent.com/u/5178240?s=40&v=4","login":"springer13"},{"avatar_url":"https://avatars.githubusercontent.com/u/5110350?s=40&v=4","login":"maheshkha"},{"avatar_url":"https://avatars.githubusercontent.com/u/20576829?s=40&v=4","login":"almogsegal"}]},{"full_name":"k2-fsa/k2","description":"FSA/FST algorithms, differentiable, with PyTorch compatibility.","currentPeriodStars":0,"language":"Cuda","languageColor":"#3A4E3A","stargazers_count":795,"forks_count":177,"owner":{"avatar_url":"https://avatars.githubusercontent.com/u/5284924?s=40&v=4","login":"csukuangfj"},"buildBy":[{"avatar_url":"https://avatars.githubusercontent.com/u/5284924?s=40&v=4","login":"csukuangfj"},{"avatar_url":"https://avatars.githubusercontent.com/u/3298747?s=40&v=4","login":"danpovey"},{"avatar_url":"https://avatars.githubusercontent.com/u/18031502?s=40&v=4","login":"qindazhu"},{"avatar_url":"https://avatars.githubusercontent.com/u/11765074?s=40&v=4","login":"pkufool"},{"avatar_url":"https://avatars.githubusercontent.com/u/14951566?s=40&v=4","login":"glynpu"}]}]}
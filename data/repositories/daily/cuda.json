{"updateTime":"2026-02-08 02:39:46","data":[{"full_name":"","description":"DeepEP: an efficient expert-parallel communication library","currentPeriodStars":4,"language":"Cuda","languageColor":"#3A4E3A","stargazers_count":8966,"forks_count":0,"owner":{"avatar_url":"https://avatars.githubusercontent.com/u/35299455?s=40&v=4","login":"LyricZhao"},"buildBy":[{"avatar_url":"https://avatars.githubusercontent.com/u/35299455?s=40&v=4","login":"LyricZhao"},{"avatar_url":"https://avatars.githubusercontent.com/u/9213347?s=40&v=4","login":"sphish"},{"avatar_url":"https://avatars.githubusercontent.com/u/5236035?s=40&v=4","login":"fzyzcjy"},{"avatar_url":"https://avatars.githubusercontent.com/u/166747556?s=40&v=4","login":"seth-howell"},{"avatar_url":"https://avatars.githubusercontent.com/u/8215757?s=40&v=4","login":"wangfakang"}]},{"full_name":"","description":"DeepGEMM: clean and efficient FP8 GEMM kernels with fine-grained scaling","currentPeriodStars":2,"language":"Cuda","languageColor":"#3A4E3A","stargazers_count":6162,"forks_count":0,"owner":{"avatar_url":"https://avatars.githubusercontent.com/u/35299455?s=40&v=4","login":"LyricZhao"},"buildBy":[{"avatar_url":"https://avatars.githubusercontent.com/u/35299455?s=40&v=4","login":"LyricZhao"},{"avatar_url":"https://avatars.githubusercontent.com/u/44948473?s=40&v=4","login":"soundOfDestiny"},{"avatar_url":"https://avatars.githubusercontent.com/u/94977922?s=40&v=4","login":"zheanxu"},{"avatar_url":"https://avatars.githubusercontent.com/u/34201481?s=40&v=4","login":"RayWang96"},{"avatar_url":"https://avatars.githubusercontent.com/u/16716991?s=40&v=4","login":"ko3n1g"}]},{"full_name":"","description":"CUDA Kernel Benchmarking Library","currentPeriodStars":1,"language":"Cuda","languageColor":"#3A4E3A","stargazers_count":809,"forks_count":0,"owner":{"avatar_url":"https://avatars.githubusercontent.com/u/58744?s=40&v=4","login":"alliepiper"},"buildBy":[{"avatar_url":"https://avatars.githubusercontent.com/u/58744?s=40&v=4","login":"alliepiper"},{"avatar_url":"https://avatars.githubusercontent.com/u/21087696?s=40&v=4","login":"oleksandr-pavlyk"},{"avatar_url":"https://avatars.githubusercontent.com/u/9890394?s=40&v=4","login":"gevtushenko"},{"avatar_url":"https://avatars.githubusercontent.com/u/3190405?s=40&v=4","login":"shwina"},{"avatar_url":"https://avatars.githubusercontent.com/u/215756?s=40&v=4","login":"robertmaynard"}]},{"full_name":"","description":"NCCL Tests","currentPeriodStars":0,"language":"Cuda","languageColor":"#3A4E3A","stargazers_count":1425,"forks_count":0,"owner":{"avatar_url":"https://avatars.githubusercontent.com/u/2538330?s=40&v=4","login":"AddyLaddy"},"buildBy":[{"avatar_url":"https://avatars.githubusercontent.com/u/2538330?s=40&v=4","login":"AddyLaddy"},{"avatar_url":"https://avatars.githubusercontent.com/u/12857445?s=40&v=4","login":"sjeaugey"},{"avatar_url":"https://avatars.githubusercontent.com/u/29100714?s=40&v=4","login":"kgioioso"},{"avatar_url":"https://avatars.githubusercontent.com/u/2293859?s=40&v=4","login":"jbachan"},{"avatar_url":"https://avatars.githubusercontent.com/u/687269?s=40&v=4","login":"lukeyeager"}]},{"full_name":"","description":"[ARCHIVED] Cooperative primitives for CUDA C++. See https://github.com/NVIDIA/cccl","currentPeriodStars":1,"language":"Cuda","languageColor":"#3A4E3A","stargazers_count":1818,"forks_count":0,"owner":{"avatar_url":"https://avatars.githubusercontent.com/u/9890394?s=40&v=4","login":"gevtushenko"},"buildBy":[{"avatar_url":"https://avatars.githubusercontent.com/u/9890394?s=40&v=4","login":"gevtushenko"},{"avatar_url":"https://avatars.githubusercontent.com/u/58744?s=40&v=4","login":"alliepiper"},{"avatar_url":"https://avatars.githubusercontent.com/u/1476032?s=40&v=4","login":"dumerrill"},{"avatar_url":"https://avatars.githubusercontent.com/u/398194?s=40&v=4","login":"brycelelbach"},{"avatar_url":"https://avatars.githubusercontent.com/u/3958403?s=40&v=4","login":"elstehle"}]},{"full_name":"","description":"[ICLR2025, ICML2025, NeurIPS2025 Spotlight] Quantized Attention achieves speedup of 2-5x compared to FlashAttention, without losing end-to-end metrics across language, image, and video models.","currentPeriodStars":3,"language":"Cuda","languageColor":"#3A4E3A","stargazers_count":3144,"forks_count":0,"owner":{"avatar_url":"https://avatars.githubusercontent.com/u/59364182?s=40&v=4","login":"jt-zhang"},"buildBy":[{"avatar_url":"https://avatars.githubusercontent.com/u/59364182?s=40&v=4","login":"jt-zhang"},{"avatar_url":"https://avatars.githubusercontent.com/u/110245937?s=40&v=4","login":"jason-huang03"},{"avatar_url":"https://avatars.githubusercontent.com/u/38180676?s=40&v=4","login":"whx1003"},{"avatar_url":"https://avatars.githubusercontent.com/u/37583905?s=40&v=4","login":"XiaomingXu1995"},{"avatar_url":"https://avatars.githubusercontent.com/u/2712115?s=40&v=4","login":"guilhermeleobas"}]},{"full_name":"","description":"LLM training in simple, raw C/CUDA","currentPeriodStars":5,"language":"Cuda","languageColor":"#3A4E3A","stargazers_count":28797,"forks_count":0,"owner":{"avatar_url":"https://avatars.githubusercontent.com/u/241138?s=40&v=4","login":"karpathy"},"buildBy":[{"avatar_url":"https://avatars.githubusercontent.com/u/241138?s=40&v=4","login":"karpathy"},{"avatar_url":"https://avatars.githubusercontent.com/u/7938269?s=40&v=4","login":"ngc92"},{"avatar_url":"https://avatars.githubusercontent.com/u/29271842?s=40&v=4","login":"gordicaleksa"},{"avatar_url":"https://avatars.githubusercontent.com/u/7082233?s=40&v=4","login":"ademeure"},{"avatar_url":"https://avatars.githubusercontent.com/u/55313766?s=40&v=4","login":"rosslwheeler"}]}]}
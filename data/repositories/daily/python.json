{"updateTime":"2023-08-19 02:18:58","data":[{"full_name":"","description":"This repository contains the official implementation of the research paper, \"FastViT: A Fast Hybrid Vision Transformer using Structural Reparameterization\"","currentPeriodStars":124,"language":"Python","languageColor":"#3572A5","stargazers_count":949,"forks_count":0,"owner":{"avatar_url":"https://avatars.githubusercontent.com/u/14334441?s=40&v=4","login":"anuragranj"},"buildBy":[{"avatar_url":"https://avatars.githubusercontent.com/u/14334441?s=40&v=4","login":"anuragranj"},{"avatar_url":"https://avatars.githubusercontent.com/u/109316305?s=40&v=4","login":"pavank-apple"}]},{"full_name":"","description":"Á±ª‰ººÊåâÈîÆÁ≤æÁÅµÁöÑÈº†Ê†áÈîÆÁõòÂΩïÂà∂ÂíåËá™Âä®ÂåñÊìç‰Ωú Ê®°ÊãüÁÇπÂáªÂíåÈîÆÂÖ• | automate mouse clicks and keyboard input","currentPeriodStars":32,"language":"Python","languageColor":"#3572A5","stargazers_count":4098,"forks_count":0,"owner":{"avatar_url":"https://avatars.githubusercontent.com/u/70839036?s=40&v=4","login":"Monomux"},"buildBy":[{"avatar_url":"https://avatars.githubusercontent.com/u/70839036?s=40&v=4","login":"Monomux"},{"avatar_url":"https://avatars.githubusercontent.com/u/3334897?s=40&v=4","login":"taojy123"},{"avatar_url":"https://avatars.githubusercontent.com/u/54732130?s=40&v=4","login":"ZutJoe"},{"avatar_url":"https://avatars.githubusercontent.com/in/29110?s=40&v=4","login":"dependabot"}]},{"full_name":"","description":"GPT-vup BIliBili | ÊäñÈü≥ | AI | ËôöÊãü‰∏ªÊí≠","currentPeriodStars":33,"language":"Python","languageColor":"#3572A5","stargazers_count":487,"forks_count":0,"owner":{"avatar_url":"https://avatars.githubusercontent.com/u/68210837?s=40&v=4","login":"jiran214"},"buildBy":[{"avatar_url":"https://avatars.githubusercontent.com/u/68210837?s=40&v=4","login":"jiran214"}]},{"full_name":"","description":"Use Microsoft Edge's online text-to-speech service from Python WITHOUT needing Microsoft Edge or Windows or an API key","currentPeriodStars":13,"language":"Python","languageColor":"#3572A5","stargazers_count":1804,"forks_count":0,"owner":{"avatar_url":"https://avatars.githubusercontent.com/u/71077389?s=40&v=4","login":"rany2"},"buildBy":[{"avatar_url":"https://avatars.githubusercontent.com/u/71077389?s=40&v=4","login":"rany2"},{"avatar_url":"https://avatars.githubusercontent.com/u/29223849?s=40&v=4","login":"Vuizur"},{"avatar_url":"https://avatars.githubusercontent.com/in/29110?s=40&v=4","login":"dependabot"},{"avatar_url":"https://avatars.githubusercontent.com/u/3937526?s=40&v=4","login":"zhisenyang"},{"avatar_url":"https://avatars.githubusercontent.com/u/18044730?s=40&v=4","login":"maltoze"}]},{"full_name":"","description":"We write your reusable computer vision tools. üíú","currentPeriodStars":421,"language":"Python","languageColor":"#3572A5","stargazers_count":2761,"forks_count":0,"owner":{"avatar_url":"https://avatars.githubusercontent.com/u/26109316?s=40&v=4","login":"SkalskiP"},"buildBy":[{"avatar_url":"https://avatars.githubusercontent.com/u/26109316?s=40&v=4","login":"SkalskiP"},{"avatar_url":"https://avatars.githubusercontent.com/u/44346535?s=40&v=4","login":"kirilllzaitsev"},{"avatar_url":"https://avatars.githubusercontent.com/u/39372750?s=40&v=4","login":"hardikdava"},{"avatar_url":"https://avatars.githubusercontent.com/u/39498938?s=40&v=4","login":"mayankagarwals"},{"avatar_url":"https://avatars.githubusercontent.com/u/37276661?s=40&v=4","login":"capjamesg"}]},{"full_name":"","description":"Focus on prompting and generating","currentPeriodStars":428,"language":"Python","languageColor":"#3572A5","stargazers_count":5647,"forks_count":0,"owner":{"avatar_url":"https://avatars.githubusercontent.com/u/19834515?s=40&v=4","login":"lllyasviel"},"buildBy":[{"avatar_url":"https://avatars.githubusercontent.com/u/19834515?s=40&v=4","login":"lllyasviel"},{"avatar_url":"https://avatars.githubusercontent.com/u/1455397?s=40&v=4","login":"tcmaps"}]},{"full_name":"","description":"üëã Hey there new gradüéâ! We've put together a collection of full-time job openings for SWE, Quant, PM and tech roles in 2024! üöÄ","currentPeriodStars":33,"language":"Python","languageColor":"#3572A5","stargazers_count":3097,"forks_count":0,"owner":{"avatar_url":"https://avatars.githubusercontent.com/u/59776018?s=40&v=4","login":"ReaVNaiL"},"buildBy":[{"avatar_url":"https://avatars.githubusercontent.com/u/59776018?s=40&v=4","login":"ReaVNaiL"},{"avatar_url":"https://avatars.githubusercontent.com/u/117412619?s=40&v=4","login":"mtlogs"},{"avatar_url":"https://avatars.githubusercontent.com/u/99780168?s=40&v=4","login":"hvnguyen57"},{"avatar_url":"https://avatars.githubusercontent.com/u/39425112?s=40&v=4","login":"derthadams"},{"avatar_url":"https://avatars.githubusercontent.com/u/94256529?s=40&v=4","login":"KaiserZZK"}]},{"full_name":"","description":"A framework to evaluate the generalization capability of safety alignment for LLMs","currentPeriodStars":36,"language":"Python","languageColor":"#3572A5","stargazers_count":161,"forks_count":0,"owner":{"avatar_url":"https://avatars.githubusercontent.com/u/62065094?s=40&v=4","login":"YouliangYuan"},"buildBy":[{"avatar_url":"https://avatars.githubusercontent.com/u/62065094?s=40&v=4","login":"YouliangYuan"},{"avatar_url":"https://avatars.githubusercontent.com/u/5644122?s=40&v=4","login":"tuzhaopeng"},{"avatar_url":"https://avatars.githubusercontent.com/u/5793028?s=40&v=4","login":"PinjiaHe"},{"avatar_url":"https://avatars.githubusercontent.com/u/31032829?s=40&v=4","login":"wxjiao"}]},{"full_name":"","description":"RWKV is an RNN with transformer-level LLM performance. It can be directly trained like a GPT (parallelizable). So it's combining the best of RNN and transformer - great performance, fast inference, saves VRAM, fast training, \"infinite\" ctx_len, and free sentence embedding.","currentPeriodStars":33,"language":"Python","languageColor":"#3572A5","stargazers_count":9515,"forks_count":0,"owner":{"avatar_url":"https://avatars.githubusercontent.com/u/33809201?s=40&v=4","login":"BlinkDL"},"buildBy":[{"avatar_url":"https://avatars.githubusercontent.com/u/33809201?s=40&v=4","login":"BlinkDL"},{"avatar_url":"https://avatars.githubusercontent.com/u/15486?s=40&v=4","login":"www"},{"avatar_url":"https://avatars.githubusercontent.com/u/10616794?s=40&v=4","login":"saharNooby"}]},{"full_name":"","description":"GPT based autonomous agent that does online comprehensive research on any given topic","currentPeriodStars":234,"language":"Python","languageColor":"#3572A5","stargazers_count":3625,"forks_count":0,"owner":{"avatar_url":"https://avatars.githubusercontent.com/u/13554167?s=40&v=4","login":"assafelovic"},"buildBy":[{"avatar_url":"https://avatars.githubusercontent.com/u/13554167?s=40&v=4","login":"assafelovic"},{"avatar_url":"https://avatars.githubusercontent.com/u/91344214?s=40&v=4","login":"rotemweiss57"},{"avatar_url":"https://avatars.githubusercontent.com/u/52860985?s=40&v=4","login":"gregdrizz"},{"avatar_url":"https://avatars.githubusercontent.com/in/29110?s=40&v=4","login":"dependabot"},{"avatar_url":"https://avatars.githubusercontent.com/u/61274922?s=40&v=4","login":"Aurelian-Shuttleworth"}]},{"full_name":"","description":"openpilot is an open source driver assistance system. openpilot performs the functions of Automated Lane Centering and Adaptive Cruise Control for 250+ supported car makes and models.","currentPeriodStars":5,"language":"Python","languageColor":"#3572A5","stargazers_count":41316,"forks_count":0,"owner":{"avatar_url":"https://avatars.githubusercontent.com/u/8762862?s=40&v=4","login":"adeebshihadeh"},"buildBy":[{"avatar_url":"https://avatars.githubusercontent.com/u/8762862?s=40&v=4","login":"adeebshihadeh"},{"avatar_url":"https://avatars.githubusercontent.com/u/1314752?s=40&v=4","login":"pd0wm"},{"avatar_url":"https://avatars.githubusercontent.com/u/25857203?s=40&v=4","login":"sshane"},{"avatar_url":"https://avatars.githubusercontent.com/u/27770?s=40&v=4","login":"deanlee"},{"avatar_url":"https://avatars.githubusercontent.com/u/6804392?s=40&v=4","login":"haraschax"}]},{"full_name":"","description":"A web interface for chatting with Alpaca through llama.cpp. Fully dockerized, with an easy to use API.","currentPeriodStars":8,"language":"Python","languageColor":"#3572A5","stargazers_count":4788,"forks_count":0,"owner":{"avatar_url":"https://avatars.githubusercontent.com/in/29110?s=40&v=4","login":"dependabot"},"buildBy":[{"avatar_url":"https://avatars.githubusercontent.com/in/29110?s=40&v=4","login":"dependabot"},{"avatar_url":"https://avatars.githubusercontent.com/u/835733?s=40&v=4","login":"gaby"},{"avatar_url":"https://avatars.githubusercontent.com/u/25119303?s=40&v=4","login":"nsarrazin"},{"avatar_url":"https://avatars.githubusercontent.com/u/4999086?s=40&v=4","login":"pabl-o-ce"},{"avatar_url":"https://avatars.githubusercontent.com/u/92705460?s=40&v=4","login":"mzen17"}]},{"full_name":"","description":"Chat with your documents on your local device using GPT models. No data leaves your device and 100% private.","currentPeriodStars":73,"language":"Python","languageColor":"#3572A5","stargazers_count":15202,"forks_count":0,"owner":{"avatar_url":"https://avatars.githubusercontent.com/u/134474669?s=40&v=4","login":"PromtEngineer"},"buildBy":[{"avatar_url":"https://avatars.githubusercontent.com/u/134474669?s=40&v=4","login":"PromtEngineer"},{"avatar_url":"https://avatars.githubusercontent.com/u/64715088?s=40&v=4","login":"imjwang"},{"avatar_url":"https://avatars.githubusercontent.com/u/9726781?s=40&v=4","login":"LeafmanZ"},{"avatar_url":"https://avatars.githubusercontent.com/u/77757836?s=40&v=4","login":"teleprint-me"},{"avatar_url":"https://avatars.githubusercontent.com/u/17365218?s=40&v=4","login":"Allaye"}]},{"full_name":"","description":"Visual Instruction Tuning: Large Language-and-Vision Assistant built towards multimodal GPT-4 level capabilities.","currentPeriodStars":26,"language":"Python","languageColor":"#3572A5","stargazers_count":4514,"forks_count":0,"owner":{"avatar_url":"https://avatars.githubusercontent.com/u/6631389?s=40&v=4","login":"haotian-liu"},"buildBy":[{"avatar_url":"https://avatars.githubusercontent.com/u/6631389?s=40&v=4","login":"haotian-liu"},{"avatar_url":"https://avatars.githubusercontent.com/u/8978644?s=40&v=4","login":"ChunyuanLI"},{"avatar_url":"https://avatars.githubusercontent.com/u/64568?s=40&v=4","login":"abdul"},{"avatar_url":"https://avatars.githubusercontent.com/u/8092481?s=40&v=4","login":"satyajitghana"},{"avatar_url":"https://avatars.githubusercontent.com/u/13670242?s=40&v=4","login":"PhanTask"}]},{"full_name":"","description":"Robust Speech Recognition via Large-Scale Weak Supervision","currentPeriodStars":82,"language":"Python","languageColor":"#3572A5","stargazers_count":43078,"forks_count":0,"owner":{"avatar_url":"https://avatars.githubusercontent.com/u/266841?s=40&v=4","login":"jongwook"},"buildBy":[{"avatar_url":"https://avatars.githubusercontent.com/u/266841?s=40&v=4","login":"jongwook"},{"avatar_url":"https://avatars.githubusercontent.com/u/19899190?s=40&v=4","login":"ryanheise"},{"avatar_url":"https://avatars.githubusercontent.com/u/731031?s=40&v=4","login":"petterreinholdtsen"},{"avatar_url":"https://avatars.githubusercontent.com/u/1714412?s=40&v=4","login":"HennerM"},{"avatar_url":"https://avatars.githubusercontent.com/u/2590984?s=40&v=4","login":"VulumeCode"}]},{"full_name":"","description":"Rinha de Backend - Edi√ß√£o 2023 Q3","currentPeriodStars":27,"language":"Python","languageColor":"#3572A5","stargazers_count":406,"forks_count":0,"owner":{"avatar_url":"https://avatars.githubusercontent.com/u/1862567?s=40&v=4","login":"zanfranceschi"},"buildBy":[{"avatar_url":"https://avatars.githubusercontent.com/u/1862567?s=40&v=4","login":"zanfranceschi"},{"avatar_url":"https://avatars.githubusercontent.com/u/26147143?s=40&v=4","login":"leorcvargas"},{"avatar_url":"https://avatars.githubusercontent.com/u/48830140?s=40&v=4","login":"victorjoao97"},{"avatar_url":"https://avatars.githubusercontent.com/u/12899375?s=40&v=4","login":"viniciusfonseca"},{"avatar_url":"https://avatars.githubusercontent.com/u/4077961?s=40&v=4","login":"MarcosCostaDev"}]},{"full_name":"","description":"Visual Blocks for ML is a Google visual programming framework that lets you create ML pipelines in a no-code graph editor. You ‚Äì and your users ‚Äì can quickly prototype workflows by connecting drag-and-drop ML components, including models, user inputs, processors, and visualizations.","currentPeriodStars":25,"language":"Python","languageColor":"#3572A5","stargazers_count":573,"forks_count":0,"owner":{"avatar_url":"https://avatars.githubusercontent.com/u/1618817?s=40&v=4","login":"ruofeidu"},"buildBy":[{"avatar_url":"https://avatars.githubusercontent.com/u/1618817?s=40&v=4","login":"ruofeidu"},{"avatar_url":"https://avatars.githubusercontent.com/u/8752427?s=40&v=4","login":"jinjingforever"},{"avatar_url":"https://avatars.githubusercontent.com/u/138255170?s=40&v=4","login":"yiyihg"},{"avatar_url":"https://avatars.githubusercontent.com/u/59679106?s=40&v=4","login":"wrighkv1"},{"avatar_url":"https://avatars.githubusercontent.com/u/33302970?s=40&v=4","login":"zhongyi-zhou"}]},{"full_name":"","description":"Datasets, Transforms and Models specific to Computer Vision","currentPeriodStars":5,"language":"Python","languageColor":"#3572A5","stargazers_count":14419,"forks_count":0,"owner":{"avatar_url":"https://avatars.githubusercontent.com/u/21957446?s=40&v=4","login":"pytorchbot"},"buildBy":[{"avatar_url":"https://avatars.githubusercontent.com/u/21957446?s=40&v=4","login":"pytorchbot"},{"avatar_url":"https://avatars.githubusercontent.com/u/6849766?s=40&v=4","login":"pmeier"},{"avatar_url":"https://avatars.githubusercontent.com/u/5347466?s=40&v=4","login":"datumbox"},{"avatar_url":"https://avatars.githubusercontent.com/u/9110200?s=40&v=4","login":"fmassa"},{"avatar_url":"https://avatars.githubusercontent.com/u/1190450?s=40&v=4","login":"NicolasHug"}]},{"full_name":"","description":"üêç Complete C99 parser in pure Python","currentPeriodStars":3,"language":"Python","languageColor":"#3572A5","stargazers_count":2949,"forks_count":0,"owner":{"avatar_url":"https://avatars.githubusercontent.com/u/1130906?s=40&v=4","login":"eliben"},"buildBy":[{"avatar_url":"https://avatars.githubusercontent.com/u/1130906?s=40&v=4","login":"eliben"},{"avatar_url":"https://avatars.githubusercontent.com/u/347634?s=40&v=4","login":"jdufresne"},{"avatar_url":"https://avatars.githubusercontent.com/u/785824?s=40&v=4","login":"akiradeveloper"},{"avatar_url":"https://avatars.githubusercontent.com/u/13061643?s=40&v=4","login":"ldore"}]},{"full_name":"","description":"Specify what you want it to build, the AI asks for clarification, and then builds it.","currentPeriodStars":200,"language":"Python","languageColor":"#3572A5","stargazers_count":41615,"forks_count":0,"owner":{"avatar_url":"https://avatars.githubusercontent.com/u/4467025?s=40&v=4","login":"AntonOsika"},"buildBy":[{"avatar_url":"https://avatars.githubusercontent.com/u/4467025?s=40&v=4","login":"AntonOsika"},{"avatar_url":"https://avatars.githubusercontent.com/u/10074977?s=40&v=4","login":"patillacode"},{"avatar_url":"https://avatars.githubusercontent.com/u/11357793?s=40&v=4","login":"leomariga"},{"avatar_url":"https://avatars.githubusercontent.com/u/490809?s=40&v=4","login":"pbharrin"},{"avatar_url":"https://avatars.githubusercontent.com/u/1856197?s=40&v=4","login":"FOLLGAD"}]},{"full_name":"","description":"Vector search for humans.","currentPeriodStars":81,"language":"Python","languageColor":"#3572A5","stargazers_count":3434,"forks_count":0,"owner":{"avatar_url":"https://avatars.githubusercontent.com/u/107458762?s=40&v=4","login":"pandu-k"},"buildBy":[{"avatar_url":"https://avatars.githubusercontent.com/u/107458762?s=40&v=4","login":"pandu-k"},{"avatar_url":"https://avatars.githubusercontent.com/u/49334982?s=40&v=4","login":"wanliAlex"},{"avatar_url":"https://avatars.githubusercontent.com/u/18024571?s=40&v=4","login":"tomhamer"},{"avatar_url":"https://avatars.githubusercontent.com/u/13092433?s=40&v=4","login":"jn2clark"},{"avatar_url":"https://avatars.githubusercontent.com/u/26185909?s=40&v=4","login":"vicilliar"}]},{"full_name":"","description":"WhisperX: Automatic Speech Recognition with Word-level Timestamps (& Diarization)","currentPeriodStars":64,"language":"Python","languageColor":"#3572A5","stargazers_count":4520,"forks_count":0,"owner":{"avatar_url":"https://avatars.githubusercontent.com/u/36994049?s=40&v=4","login":"m-bain"},"buildBy":[{"avatar_url":"https://avatars.githubusercontent.com/u/36994049?s=40&v=4","login":"m-bain"},{"avatar_url":"https://avatars.githubusercontent.com/u/19920981?s=40&v=4","login":"yasutak"},{"avatar_url":"https://avatars.githubusercontent.com/u/80467011?s=40&v=4","login":"sorgfresser"},{"avatar_url":"https://avatars.githubusercontent.com/u/32404268?s=40&v=4","login":"MahmoudAshraf97"},{"avatar_url":"https://avatars.githubusercontent.com/u/8578353?s=40&v=4","login":"abCods"}]},{"full_name":"","description":"A framework for managing and maintaining multi-language pre-commit hooks.","currentPeriodStars":6,"language":"Python","languageColor":"#3572A5","stargazers_count":10795,"forks_count":0,"owner":{"avatar_url":"https://avatars.githubusercontent.com/u/1810591?s=40&v=4","login":"asottile"},"buildBy":[{"avatar_url":"https://avatars.githubusercontent.com/u/1810591?s=40&v=4","login":"asottile"},{"avatar_url":"https://avatars.githubusercontent.com/in/68672?s=40&v=4","login":"pre-commit-ci"},{"avatar_url":"https://avatars.githubusercontent.com/u/232692?s=40&v=4","login":"struys"},{"avatar_url":"https://avatars.githubusercontent.com/u/7457961?s=40&v=4","login":"geieredgar"},{"avatar_url":"https://avatars.githubusercontent.com/u/10477073?s=40&v=4","login":"lorenzwalthert"}]},{"full_name":"","description":"\"Effective Whole-body Pose Estimation with Two-stages Distillation\" (ICCV 2023, CV4Metaverse Workshop)","currentPeriodStars":40,"language":"Python","languageColor":"#3572A5","stargazers_count":804,"forks_count":0,"owner":{"avatar_url":"https://avatars.githubusercontent.com/u/54797851?s=40&v=4","login":"yzd-v"},"buildBy":[{"avatar_url":"https://avatars.githubusercontent.com/u/54797851?s=40&v=4","login":"yzd-v"},{"avatar_url":"https://avatars.githubusercontent.com/u/32029490?s=40&v=4","login":"ailingzengzzz"}]},{"full_name":"","description":"The uncompromising Python code formatter","currentPeriodStars":16,"language":"Python","languageColor":"#3572A5","stargazers_count":33263,"forks_count":0,"owner":{"avatar_url":"https://avatars.githubusercontent.com/u/55281?s=40&v=4","login":"ambv"},"buildBy":[{"avatar_url":"https://avatars.githubusercontent.com/u/55281?s=40&v=4","login":"ambv"},{"avatar_url":"https://avatars.githubusercontent.com/u/63936253?s=40&v=4","login":"ichard26"},{"avatar_url":"https://avatars.githubusercontent.com/u/906600?s=40&v=4","login":"JelleZijlstra"},{"avatar_url":"https://avatars.githubusercontent.com/u/1324225?s=40&v=4","login":"hugovk"},{"avatar_url":"https://avatars.githubusercontent.com/in/29110?s=40&v=4","login":"dependabot"}]}]}
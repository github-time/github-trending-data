{"updateTime":"2025-12-19 02:36:58","data":[{"full_name":"","description":"[WIP] Resources for AI engineers. Also contains supporting materials for the book AI Engineering (Chip Huyen, 2025)","currentPeriodStars":27,"language":"Jupyter Notebook","languageColor":"#DA5B0B","stargazers_count":12488,"forks_count":0,"owner":{"avatar_url":"https://avatars.githubusercontent.com/u/11997567?s=40&v=4","login":"chiphuyen"},"buildBy":[{"avatar_url":"https://avatars.githubusercontent.com/u/11997567?s=40&v=4","login":"chiphuyen"},{"avatar_url":"https://avatars.githubusercontent.com/u/19699016?s=40&v=4","login":"chris-alexiuk"},{"avatar_url":"https://avatars.githubusercontent.com/u/145115?s=40&v=4","login":"dr3s"},{"avatar_url":"https://avatars.githubusercontent.com/u/3348134?s=40&v=4","login":"strickvl"},{"avatar_url":"https://avatars.githubusercontent.com/u/24555636?s=40&v=4","login":"omrylcn"}]},{"full_name":"","description":"A latent text-to-image diffusion model","currentPeriodStars":7,"language":"Jupyter Notebook","languageColor":"#DA5B0B","stargazers_count":72024,"forks_count":0,"owner":{"avatar_url":"https://avatars.githubusercontent.com/u/38811725?s=40&v=4","login":"rromb"},"buildBy":[{"avatar_url":"https://avatars.githubusercontent.com/u/38811725?s=40&v=4","login":"rromb"},{"avatar_url":"https://avatars.githubusercontent.com/u/2175508?s=40&v=4","login":"pesser"},{"avatar_url":"https://avatars.githubusercontent.com/u/23423619?s=40&v=4","login":"patrickvonplaten"},{"avatar_url":"https://avatars.githubusercontent.com/u/26577641?s=40&v=4","login":"ablattmann"},{"avatar_url":"https://avatars.githubusercontent.com/u/25171708?s=40&v=4","login":"LuChengTHU"}]},{"full_name":"","description":"GenAI Cookbook","currentPeriodStars":5,"language":"Jupyter Notebook","languageColor":"#DA5B0B","stargazers_count":4199,"forks_count":0,"owner":{"avatar_url":"https://avatars.githubusercontent.com/u/16384755?s=40&v=4","login":"RichmondAlake"},"buildBy":[{"avatar_url":"https://avatars.githubusercontent.com/u/16384755?s=40&v=4","login":"RichmondAlake"},{"avatar_url":"https://avatars.githubusercontent.com/u/16643200?s=40&v=4","login":"Pash10g"},{"avatar_url":"https://avatars.githubusercontent.com/u/30438249?s=40&v=4","login":"ajosh0504"},{"avatar_url":"https://avatars.githubusercontent.com/u/86017775?s=40&v=4","login":"anaiyaraisin"},{"avatar_url":"https://avatars.githubusercontent.com/u/1014889?s=40&v=4","login":"snarvaez"}]},{"full_name":"","description":"NVIDIA Isaac GR00T N1.6 - A Foundation Model for Generalist Robots.","currentPeriodStars":21,"language":"Jupyter Notebook","languageColor":"#DA5B0B","stargazers_count":5639,"forks_count":0,"owner":{"avatar_url":"https://avatars.githubusercontent.com/u/32189404?s=40&v=4","login":"youliangtan"},"buildBy":[{"avatar_url":"https://avatars.githubusercontent.com/u/32189404?s=40&v=4","login":"youliangtan"},{"avatar_url":"https://avatars.githubusercontent.com/u/127644049?s=40&v=4","login":"HuFY-dev"},{"avatar_url":"https://avatars.githubusercontent.com/u/87673679?s=40&v=4","login":"xwjiang2010"},{"avatar_url":"https://avatars.githubusercontent.com/u/39802957?s=40&v=4","login":"kaushil24"},{"avatar_url":"https://avatars.githubusercontent.com/u/89691310?s=40&v=4","login":"kevinsongbing"}]},{"full_name":"","description":"This open-source curriculum introduces the fundamentals of Model Context Protocol (MCP) through real-world, cross-language examples in .NET, Java, TypeScript, JavaScript, Rust and Python. Designed for developers, it focuses on practical techniques for building modular, scalable, and secure AI workflows from session setup to service orchestration.","currentPeriodStars":30,"language":"Jupyter Notebook","languageColor":"#DA5B0B","stargazers_count":13771,"forks_count":0,"owner":{"avatar_url":"https://avatars.githubusercontent.com/u/2511341?s=40&v=4","login":"leestott"},"buildBy":[{"avatar_url":"https://avatars.githubusercontent.com/u/2511341?s=40&v=4","login":"leestott"},{"avatar_url":"https://avatars.githubusercontent.com/u/4598064?s=40&v=4","login":"softchris"},{"avatar_url":"https://avatars.githubusercontent.com/u/6388864?s=40&v=4","login":"roryp"},{"avatar_url":"https://avatars.githubusercontent.com/in/946600?s=40&v=4","login":"Copilot"},{"avatar_url":"https://avatars.githubusercontent.com/u/40815708?s=40&v=4","login":"hyoshioka0128"}]},{"full_name":"","description":"Implementation of paper - YOLOv7: Trainable bag-of-freebies sets new state-of-the-art for real-time object detectors","currentPeriodStars":7,"language":"Jupyter Notebook","languageColor":"#DA5B0B","stargazers_count":14076,"forks_count":0,"owner":{"avatar_url":"https://avatars.githubusercontent.com/u/12152972?s=40&v=4","login":"WongKinYiu"},"buildBy":[{"avatar_url":"https://avatars.githubusercontent.com/u/12152972?s=40&v=4","login":"WongKinYiu"},{"avatar_url":"https://avatars.githubusercontent.com/u/4096485?s=40&v=4","login":"AlexeyAB"},{"avatar_url":"https://avatars.githubusercontent.com/u/68598764?s=40&v=4","login":"mkhoshbin72"},{"avatar_url":"https://avatars.githubusercontent.com/u/92794867?s=40&v=4","login":"triple-Mu"},{"avatar_url":"https://avatars.githubusercontent.com/u/1684326?s=40&v=4","login":"taka-wang"}]},{"full_name":"","description":"State-of-the-art Image & Video CLIP, Multimodal Large Language Models, and More!","currentPeriodStars":25,"language":"Jupyter Notebook","languageColor":"#DA5B0B","stargazers_count":1879,"forks_count":0,"owner":{"avatar_url":"https://avatars.githubusercontent.com/u/55104795?s=40&v=4","login":"mmaaz60"},"buildBy":[{"avatar_url":"https://avatars.githubusercontent.com/u/55104795?s=40&v=4","login":"mmaaz60"},{"avatar_url":"https://avatars.githubusercontent.com/u/4979623?s=40&v=4","login":"berniebear"},{"avatar_url":"https://avatars.githubusercontent.com/u/19721752?s=40&v=4","login":"dbolya"},{"avatar_url":"https://avatars.githubusercontent.com/u/77150595?s=40&v=4","login":"janghyuncho"},{"avatar_url":"https://avatars.githubusercontent.com/u/6934703?s=40&v=4","login":"andreamad8"}]},{"full_name":"","description":"Ready-to-run cloud templates for RAG, AI pipelines, and enterprise search with live data. üê≥Docker-friendly.‚ö°Always in sync with Sharepoint, Google Drive, S3, Kafka, PostgreSQL, real-time data APIs, and more.","currentPeriodStars":44,"language":"Jupyter Notebook","languageColor":"#DA5B0B","stargazers_count":47801,"forks_count":0,"owner":{"avatar_url":"https://avatars.githubusercontent.com/u/63911408?s=40&v=4","login":"berkecanrizai"},"buildBy":[{"avatar_url":"https://avatars.githubusercontent.com/u/63911408?s=40&v=4","login":"berkecanrizai"},{"avatar_url":"https://avatars.githubusercontent.com/u/2479355?s=40&v=4","login":"szymondudycz"},{"avatar_url":"https://avatars.githubusercontent.com/u/106311100?s=40&v=4","login":"pw-ppodhajski"},{"avatar_url":"https://avatars.githubusercontent.com/u/15914792?s=40&v=4","login":"dxtrous"},{"avatar_url":"https://avatars.githubusercontent.com/u/123164531?s=40&v=4","login":"mdmalhou"}]},{"full_name":"","description":"Materials for the Learn PyTorch for Deep Learning: Zero to Mastery course.","currentPeriodStars":17,"language":"Jupyter Notebook","languageColor":"#DA5B0B","stargazers_count":16570,"forks_count":0,"owner":{"avatar_url":"https://avatars.githubusercontent.com/u/16750345?s=40&v=4","login":"mrdbourke"},"buildBy":[{"avatar_url":"https://avatars.githubusercontent.com/u/16750345?s=40&v=4","login":"mrdbourke"},{"avatar_url":"https://avatars.githubusercontent.com/u/92997306?s=40&v=4","login":"pritesh2000"},{"avatar_url":"https://avatars.githubusercontent.com/u/36633619?s=40&v=4","login":"Alejandro-Casanova"},{"avatar_url":"https://avatars.githubusercontent.com/u/44616784?s=40&v=4","login":"anakin87"},{"avatar_url":"https://avatars.githubusercontent.com/u/59410571?s=40&v=4","login":"daspartho"}]},{"full_name":"","description":"PyTorch code for BLIP: Bootstrapping Language-Image Pre-training for Unified Vision-Language Understanding and Generation","currentPeriodStars":1,"language":"Jupyter Notebook","languageColor":"#DA5B0B","stargazers_count":5614,"forks_count":0,"owner":{"avatar_url":"https://avatars.githubusercontent.com/u/13638455?s=40&v=4","login":"LiJunnan1992"},"buildBy":[{"avatar_url":"https://avatars.githubusercontent.com/u/13638455?s=40&v=4","login":"LiJunnan1992"},{"avatar_url":"https://avatars.githubusercontent.com/u/81195143?s=40&v=4","login":"AK391"}]},{"full_name":"","description":"A powerful tool for automated LLM fuzzing. It is designed to help developers and security researchers identify and mitigate potential jailbreaks in their LLM APIs.","currentPeriodStars":11,"language":"Jupyter Notebook","languageColor":"#DA5B0B","stargazers_count":1070,"forks_count":0,"owner":{"avatar_url":"https://avatars.githubusercontent.com/u/190499536?s=40&v=4","login":"sha1cybr"},"buildBy":[{"avatar_url":"https://avatars.githubusercontent.com/u/190499536?s=40&v=4","login":"sha1cybr"},{"avatar_url":"https://avatars.githubusercontent.com/u/136694812?s=40&v=4","login":"ESPanda666"},{"avatar_url":"https://avatars.githubusercontent.com/u/4501996?s=40&v=4","login":"nivmorabin"},{"avatar_url":"https://avatars.githubusercontent.com/u/40800448?s=40&v=4","login":"Fato07"},{"avatar_url":"https://avatars.githubusercontent.com/u/147075902?s=40&v=4","login":"asafgardin"}]},{"full_name":"","description":"The repository provides code for running inference with the SegmentAnything Model (SAM), links for downloading the trained model checkpoints, and example notebooks that show how to use the model.","currentPeriodStars":21,"language":"Jupyter Notebook","languageColor":"#DA5B0B","stargazers_count":52949,"forks_count":0,"owner":{"avatar_url":"https://avatars.githubusercontent.com/u/36495476?s=40&v=4","login":"ericmintun"},"buildBy":[{"avatar_url":"https://avatars.githubusercontent.com/u/36495476?s=40&v=4","login":"ericmintun"},{"avatar_url":"https://avatars.githubusercontent.com/u/16569221?s=40&v=4","login":"HannaMao"},{"avatar_url":"https://avatars.githubusercontent.com/u/5912647?s=40&v=4","login":"nikhilaravi"},{"avatar_url":"https://avatars.githubusercontent.com/u/6997335?s=40&v=4","login":"ronghanghu"},{"avatar_url":"https://avatars.githubusercontent.com/u/62285254?s=40&v=4","login":"Elm-Forest"}]},{"full_name":"","description":"Official community-driven Azure Machine Learning examples, tested with GitHub Actions.","currentPeriodStars":0,"language":"Jupyter Notebook","languageColor":"#DA5B0B","stargazers_count":1957,"forks_count":0,"owner":{"avatar_url":"https://avatars.githubusercontent.com/u/39775772?s=40&v=4","login":"jeff-shepherd"},"buildBy":[{"avatar_url":"https://avatars.githubusercontent.com/u/39775772?s=40&v=4","login":"jeff-shepherd"},{"avatar_url":"https://avatars.githubusercontent.com/u/54814569?s=40&v=4","login":"lostmygithubaccount"},{"avatar_url":"https://avatars.githubusercontent.com/u/33712765?s=40&v=4","login":"balapv"},{"avatar_url":"https://avatars.githubusercontent.com/u/3650506?s=40&v=4","login":"sdgilley"},{"avatar_url":"https://avatars.githubusercontent.com/u/83852443?s=40&v=4","login":"zetiaatgithub"}]},{"full_name":"","description":"The repository provides code for running inference with the Meta Segment Anything Model 2 (SAM 2), links for downloading the trained model checkpoints, and example notebooks that show how to use the model.","currentPeriodStars":14,"language":"Jupyter Notebook","languageColor":"#DA5B0B","stargazers_count":18047,"forks_count":0,"owner":{"avatar_url":"https://avatars.githubusercontent.com/u/6997335?s=40&v=4","login":"ronghanghu"},"buildBy":[{"avatar_url":"https://avatars.githubusercontent.com/u/6997335?s=40&v=4","login":"ronghanghu"},{"avatar_url":"https://avatars.githubusercontent.com/u/48327001?s=40&v=4","login":"NielsRogge"},{"avatar_url":"https://avatars.githubusercontent.com/u/8292193?s=40&v=4","login":"haithamkhedr"},{"avatar_url":"https://avatars.githubusercontent.com/u/25299377?s=40&v=4","login":"arun477"},{"avatar_url":"https://avatars.githubusercontent.com/u/135471798?s=40&v=4","login":"CharlesCNorton"}]},{"full_name":"","description":"üéì Êú∫Âô®Â≠¶‰π†‰∏éÊ∑±Â∫¶Â≠¶‰π†ÂÆûÊàòÊïôÁ®ã | Comprehensive ML & DL Tutorial with Jupyter Notebooks | ÂåÖÂê´Á∫øÊÄßÂõûÂΩí„ÄÅÁ•ûÁªèÁΩëÁªú„ÄÅCNN„ÄÅRNNÁ≠âÂÆåÊï¥ÊïôÁ®ã","currentPeriodStars":52,"language":"Jupyter Notebook","languageColor":"#DA5B0B","stargazers_count":131,"forks_count":0,"owner":{"avatar_url":"https://avatars.githubusercontent.com/u/182594876?s=40&v=4","login":"zimingttkx"},"buildBy":[{"avatar_url":"https://avatars.githubusercontent.com/u/182594876?s=40&v=4","login":"zimingttkx"},{"avatar_url":"https://avatars.githubusercontent.com/in/15368?s=40&v=4","login":"github-actions"}]},{"full_name":"","description":"","currentPeriodStars":0,"stargazers_count":0,"forks_count":0,"owner":{},"buildBy":[]},{"full_name":"","description":"This repository showcases various advanced techniques for Retrieval-Augmented Generation (RAG) systems. RAG systems combine information retrieval with generative models to provide accurate and contextually rich responses.","currentPeriodStars":47,"language":"Jupyter Notebook","languageColor":"#DA5B0B","stargazers_count":23604,"forks_count":0,"owner":{"avatar_url":"https://avatars.githubusercontent.com/u/28316913?s=40&v=4","login":"NirDiamant"},"buildBy":[{"avatar_url":"https://avatars.githubusercontent.com/u/28316913?s=40&v=4","login":"NirDiamant"},{"avatar_url":"https://avatars.githubusercontent.com/u/39863822?s=40&v=4","login":"tevfikcagridural"},{"avatar_url":"https://avatars.githubusercontent.com/u/97222085?s=40&v=4","login":"lzytitan494"},{"avatar_url":"https://avatars.githubusercontent.com/u/5808240?s=40&v=4","login":"Ori226"},{"avatar_url":"https://avatars.githubusercontent.com/u/6549202?s=40&v=4","login":"zmccormick7"}]}]}
{"updateTime":"2025-11-06 02:33:07","data":[{"full_name":"","description":"GenMedia Creative Studio is a Vertex AI generative media user experience highlighting the use of Imagen, Veo, Gemini üçå, Gemini TTS, Chirp 3, Lyria and other generative media APIs on Google Cloud.","currentPeriodStars":7,"language":"Jupyter Notebook","languageColor":"#DA5B0B","stargazers_count":559,"forks_count":0,"owner":{"avatar_url":"https://avatars.githubusercontent.com/u/469685?s=40&v=4","login":"ghchinoy"},"buildBy":[{"avatar_url":"https://avatars.githubusercontent.com/u/469685?s=40&v=4","login":"ghchinoy"},{"avatar_url":"https://avatars.githubusercontent.com/u/25180681?s=40&v=4","login":"renovate-bot"},{"avatar_url":"https://avatars.githubusercontent.com/u/89557446?s=40&v=4","login":"LUJ20"},{"avatar_url":"https://avatars.githubusercontent.com/in/29110?s=40&v=4","login":"dependabot"},{"avatar_url":"https://avatars.githubusercontent.com/u/149124?s=40&v=4","login":"csantos"}]},{"full_name":"","description":"Machine Learning in Finance: From Theory to Practice Book","currentPeriodStars":13,"language":"Jupyter Notebook","languageColor":"#DA5B0B","stargazers_count":2399,"forks_count":0,"owner":{"avatar_url":"https://avatars.githubusercontent.com/u/2914172?s=40&v=4","login":"mfrdixon"},"buildBy":[{"avatar_url":"https://avatars.githubusercontent.com/u/2914172?s=40&v=4","login":"mfrdixon"},{"avatar_url":"https://avatars.githubusercontent.com/u/63907524?s=40&v=4","login":"dezog"},{"avatar_url":"https://avatars.githubusercontent.com/u/17646900?s=40&v=4","login":"ighalp"}]},{"full_name":"","description":"Sample code and notebooks for Generative AI on Google Cloud, with Gemini on Vertex AI","currentPeriodStars":13,"language":"Jupyter Notebook","languageColor":"#DA5B0B","stargazers_count":11971,"forks_count":0,"owner":{"avatar_url":"https://avatars.githubusercontent.com/u/13262395?s=40&v=4","login":"holtskinner"},"buildBy":[{"avatar_url":"https://avatars.githubusercontent.com/u/13262395?s=40&v=4","login":"holtskinner"},{"avatar_url":"https://avatars.githubusercontent.com/in/99011?s=40&v=4","login":"gcf-owl-bot"},{"avatar_url":"https://avatars.githubusercontent.com/u/25180681?s=40&v=4","login":"renovate-bot"},{"avatar_url":"https://avatars.githubusercontent.com/u/106993205?s=40&v=4","login":"gericdong"},{"avatar_url":"https://avatars.githubusercontent.com/u/88703814?s=40&v=4","login":"inardini"}]},{"full_name":"","description":"Companion webpage to the book \"Mathematics For Machine Learning\"","currentPeriodStars":13,"language":"Jupyter Notebook","languageColor":"#DA5B0B","stargazers_count":14703,"forks_count":0,"owner":{"avatar_url":"https://avatars.githubusercontent.com/u/5500569?s=40&v=4","login":"mpd37"},"buildBy":[{"avatar_url":"https://avatars.githubusercontent.com/u/5500569?s=40&v=4","login":"mpd37"},{"avatar_url":"https://avatars.githubusercontent.com/u/709424?s=40&v=4","login":"chengsoonong"},{"avatar_url":"https://avatars.githubusercontent.com/u/8415380?s=40&v=4","login":"AnalogAldo"},{"avatar_url":"https://avatars.githubusercontent.com/u/15108821?s=40&v=4","login":"sanket-kamthe"},{"avatar_url":"https://avatars.githubusercontent.com/u/50109?s=40&v=4","login":"gliptak"}]},{"full_name":"","description":"Neural Networks: Zero to Hero","currentPeriodStars":40,"language":"Jupyter Notebook","languageColor":"#DA5B0B","stargazers_count":18404,"forks_count":0,"owner":{"avatar_url":"https://avatars.githubusercontent.com/u/241138?s=40&v=4","login":"karpathy"},"buildBy":[{"avatar_url":"https://avatars.githubusercontent.com/u/241138?s=40&v=4","login":"karpathy"},{"avatar_url":"https://avatars.githubusercontent.com/u/216141?s=40&v=4","login":"edvenson"}]},{"full_name":"","description":"Fabric toolbox is a repository of tools, accelerators, scripts, and samples to accelerate your success with Microsoft Fabric, brought to you by Fabric CAT.","currentPeriodStars":3,"language":"Jupyter Notebook","languageColor":"#DA5B0B","stargazers_count":530,"forks_count":0,"owner":{"avatar_url":"https://avatars.githubusercontent.com/u/14915318?s=40&v=4","login":"AzureNick"},"buildBy":[{"avatar_url":"https://avatars.githubusercontent.com/u/14915318?s=40&v=4","login":"AzureNick"},{"avatar_url":"https://avatars.githubusercontent.com/u/31256359?s=40&v=4","login":"ggintli"},{"avatar_url":"https://avatars.githubusercontent.com/u/35062421?s=40&v=4","login":"MarkPryceMaherMSFT"},{"avatar_url":"https://avatars.githubusercontent.com/u/44716363?s=40&v=4","login":"itsnotaboutthecell"},{"avatar_url":"https://avatars.githubusercontent.com/u/5063077?s=40&v=4","login":"hurtn"}]},{"full_name":"","description":"Official code repo for the O'Reilly Book - \"Hands-On Large Language Models\"","currentPeriodStars":175,"language":"Jupyter Notebook","languageColor":"#DA5B0B","stargazers_count":17501,"forks_count":0,"owner":{"avatar_url":"https://avatars.githubusercontent.com/u/25746895?s=40&v=4","login":"MaartenGr"},"buildBy":[{"avatar_url":"https://avatars.githubusercontent.com/u/25746895?s=40&v=4","login":"MaartenGr"},{"avatar_url":"https://avatars.githubusercontent.com/u/148525245?s=40&v=4","login":"negativenagesh"},{"avatar_url":"https://avatars.githubusercontent.com/u/1007956?s=40&v=4","login":"jalammar"},{"avatar_url":"https://avatars.githubusercontent.com/u/4090894?s=40&v=4","login":"dkapitan"},{"avatar_url":"https://avatars.githubusercontent.com/u/6709785?s=40&v=4","login":"dcarpintero"}]},{"full_name":"","description":"Qwen3-VL is the multimodal large language model series developed by Qwen team, Alibaba Cloud.","currentPeriodStars":46,"language":"Jupyter Notebook","languageColor":"#DA5B0B","stargazers_count":15983,"forks_count":0,"owner":{"avatar_url":"https://avatars.githubusercontent.com/u/43326198?s=40&v=4","login":"ShuaiBai623"},"buildBy":[{"avatar_url":"https://avatars.githubusercontent.com/u/43326198?s=40&v=4","login":"ShuaiBai623"},{"avatar_url":"https://avatars.githubusercontent.com/u/136600500?s=40&v=4","login":"kq-chen"},{"avatar_url":"https://avatars.githubusercontent.com/u/12120155?s=40&v=4","login":"fyabc"},{"avatar_url":"https://avatars.githubusercontent.com/u/92386084?s=40&v=4","login":"JJJYmmm"},{"avatar_url":"https://avatars.githubusercontent.com/u/13191886?s=40&v=4","login":"jinze1994"}]},{"full_name":"","description":"","currentPeriodStars":0,"stargazers_count":0,"forks_count":0,"owner":{},"buildBy":[]},{"full_name":"","description":"Grounded SAM 2: Ground and Track Anything in Videos with Grounding DINO, Florence-2 and SAM 2","currentPeriodStars":7,"language":"Jupyter Notebook","languageColor":"#DA5B0B","stargazers_count":2982,"forks_count":0,"owner":{"avatar_url":"https://avatars.githubusercontent.com/u/48727989?s=40&v=4","login":"rentainhe"},"buildBy":[{"avatar_url":"https://avatars.githubusercontent.com/u/48727989?s=40&v=4","login":"rentainhe"},{"avatar_url":"https://avatars.githubusercontent.com/u/31400000?s=40&v=4","login":"ShuoShenDe"},{"avatar_url":"https://avatars.githubusercontent.com/u/12968964?s=40&v=4","login":"williamyeny"},{"avatar_url":"https://avatars.githubusercontent.com/u/50208304?s=40&v=4","login":"MorganTitcher"},{"avatar_url":"https://avatars.githubusercontent.com/u/392199?s=40&v=4","login":"kwikwag"}]},{"full_name":"","description":"This is the official code for MobileSAM project that makes SAM lightweight for mobile applications and beyond!","currentPeriodStars":3,"language":"Jupyter Notebook","languageColor":"#DA5B0B","stargazers_count":5458,"forks_count":0,"owner":{"avatar_url":"https://avatars.githubusercontent.com/u/39910262?s=40&v=4","login":"ChaoningZhang"},"buildBy":[{"avatar_url":"https://avatars.githubusercontent.com/u/39910262?s=40&v=4","login":"ChaoningZhang"},{"avatar_url":"https://avatars.githubusercontent.com/u/102718175?s=40&v=4","login":"qiaoyu1002"},{"avatar_url":"https://avatars.githubusercontent.com/u/59354941?s=40&v=4","login":"dongshenhan"},{"avatar_url":"https://avatars.githubusercontent.com/u/12779950?s=40&v=4","login":"dhkim2810"},{"avatar_url":"https://avatars.githubusercontent.com/u/36190671?s=40&v=4","login":"ksugar"}]},{"full_name":"","description":"10 Weeks, 20 Lessons, Data Science for All!","currentPeriodStars":13,"language":"Jupyter Notebook","languageColor":"#DA5B0B","stargazers_count":31240,"forks_count":0,"owner":{"avatar_url":"https://avatars.githubusercontent.com/u/1414307?s=40&v=4","login":"paladique"},"buildBy":[{"avatar_url":"https://avatars.githubusercontent.com/u/1414307?s=40&v=4","login":"paladique"},{"avatar_url":"https://avatars.githubusercontent.com/u/2511341?s=40&v=4","login":"leestott"},{"avatar_url":"https://avatars.githubusercontent.com/u/1450004?s=40&v=4","login":"jlooper"},{"avatar_url":"https://avatars.githubusercontent.com/in/29110?s=40&v=4","login":"dependabot"},{"avatar_url":"https://avatars.githubusercontent.com/u/20380447?s=40&v=4","login":"Amagash"}]},{"full_name":"","description":"Èù¢ÂêëÂºÄÂèëËÄÖÁöÑ LLM ÂÖ•Èó®ÊïôÁ®ãÔºåÂê¥ÊÅ©ËææÂ§ßÊ®°ÂûãÁ≥ªÂàóËØæÁ®ã‰∏≠ÊñáÁâà","currentPeriodStars":13,"language":"Jupyter Notebook","languageColor":"#DA5B0B","stargazers_count":22034,"forks_count":0,"owner":{"avatar_url":"https://avatars.githubusercontent.com/u/74288839?s=40&v=4","login":"logan-zou"},"buildBy":[{"avatar_url":"https://avatars.githubusercontent.com/u/74288839?s=40&v=4","login":"logan-zou"},{"avatar_url":"https://avatars.githubusercontent.com/u/84648701?s=40&v=4","login":"Beyondzjl"},{"avatar_url":"https://avatars.githubusercontent.com/u/64852985?s=40&v=4","login":"xuhu0115"},{"avatar_url":"https://avatars.githubusercontent.com/u/65588374?s=40&v=4","login":"Weihong-Liu"},{"avatar_url":"https://avatars.githubusercontent.com/u/140427007?s=40&v=4","login":"Aphasia0515"}]},{"full_name":"","description":"Grounded SAM: Marrying Grounding DINO with Segment Anything & Stable Diffusion & Recognize Anything - Automatically Detect , Segment and Generate Anything","currentPeriodStars":5,"language":"Jupyter Notebook","languageColor":"#DA5B0B","stargazers_count":17095,"forks_count":0,"owner":{"avatar_url":"https://avatars.githubusercontent.com/u/48727989?s=40&v=4","login":"rentainhe"},"buildBy":[{"avatar_url":"https://avatars.githubusercontent.com/u/48727989?s=40&v=4","login":"rentainhe"},{"avatar_url":"https://avatars.githubusercontent.com/u/24236723?s=40&v=4","login":"Andy1621"},{"avatar_url":"https://avatars.githubusercontent.com/u/34858619?s=40&v=4","login":"SlongLiu"},{"avatar_url":"https://avatars.githubusercontent.com/u/70081899?s=40&v=4","login":"linjing7"},{"avatar_url":"https://avatars.githubusercontent.com/u/39040787?s=40&v=4","login":"CiaoHe"}]},{"full_name":"","description":"Jupyter notebooks for the code samples of the book \"Deep Learning with Python\"","currentPeriodStars":6,"language":"Jupyter Notebook","languageColor":"#DA5B0B","stargazers_count":19664,"forks_count":0,"owner":{"avatar_url":"https://avatars.githubusercontent.com/u/710255?s=40&v=4","login":"fchollet"},"buildBy":[{"avatar_url":"https://avatars.githubusercontent.com/u/710255?s=40&v=4","login":"fchollet"},{"avatar_url":"https://avatars.githubusercontent.com/u/1389937?s=40&v=4","login":"mattdangerw"},{"avatar_url":"https://avatars.githubusercontent.com/u/54595311?s=40&v=4","login":"var-nan"},{"avatar_url":"https://avatars.githubusercontent.com/u/1457728?s=40&v=4","login":"DerekChia"},{"avatar_url":"https://avatars.githubusercontent.com/u/15246198?s=40&v=4","login":"Kuz-man"}]},{"full_name":"","description":"Machine Learning Containers for NVIDIA Jetson and JetPack-L4T","currentPeriodStars":4,"language":"Jupyter Notebook","languageColor":"#DA5B0B","stargazers_count":3890,"forks_count":0,"owner":{"avatar_url":"https://avatars.githubusercontent.com/u/15352619?s=40&v=4","login":"dusty-nv"},"buildBy":[{"avatar_url":"https://avatars.githubusercontent.com/u/15352619?s=40&v=4","login":"dusty-nv"},{"avatar_url":"https://avatars.githubusercontent.com/u/22727137?s=40&v=4","login":"johnnynunez"},{"avatar_url":"https://avatars.githubusercontent.com/u/25759564?s=40&v=4","login":"tokk-nv"},{"avatar_url":"https://avatars.githubusercontent.com/u/24204300?s=40&v=4","login":"ms1design"},{"avatar_url":"https://avatars.githubusercontent.com/u/20955789?s=40&v=4","login":"OriNachum"}]},{"full_name":"","description":"Code for \"GVHMR: World-Grounded Human Motion Recovery via Gravity-View Coordinates\", Siggraph Asia 2024","currentPeriodStars":9,"language":"Jupyter Notebook","languageColor":"#DA5B0B","stargazers_count":1116,"forks_count":0,"owner":{"avatar_url":"https://avatars.githubusercontent.com/u/25296730?s=40&v=4","login":"zehongs"},"buildBy":[{"avatar_url":"https://avatars.githubusercontent.com/u/25296730?s=40&v=4","login":"zehongs"},{"avatar_url":"https://avatars.githubusercontent.com/u/11582122?s=40&v=4","login":"pengsida"},{"avatar_url":"https://avatars.githubusercontent.com/u/48550237?s=40&v=4","login":"IsshikiHugh"}]}]}
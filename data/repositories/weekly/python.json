{"updateTime":"2023-11-09 02:20:40","data":[{"full_name":"","description":"ChatGLM3 series: Open Bilingual Chat LLMs | å¼€æºåŒè¯­å¯¹è¯è¯­è¨€æ¨¡å‹","currentPeriodStars":2112,"language":"Python","languageColor":"#3572A5","stargazers_count":4514,"forks_count":0,"owner":{"avatar_url":"https://avatars.githubusercontent.com/u/28836239?s=40&v=4","login":"duzx16"},"buildBy":[{"avatar_url":"https://avatars.githubusercontent.com/u/28836239?s=40&v=4","login":"duzx16"},{"avatar_url":"https://avatars.githubusercontent.com/u/14028256?s=40&v=4","login":"Btlmd"},{"avatar_url":"https://avatars.githubusercontent.com/u/12494969?s=40&v=4","login":"davidlvxin"},{"avatar_url":"https://avatars.githubusercontent.com/u/4828553?s=40&v=4","login":"xunkai55"},{"avatar_url":"https://avatars.githubusercontent.com/u/20623941?s=40&v=4","login":"abmfy"}]},{"full_name":"","description":"VideoCrafter1: Open Diffusion Models for High-Quality Video Generation","currentPeriodStars":478,"language":"Python","languageColor":"#3572A5","stargazers_count":2905,"forks_count":0,"owner":{"avatar_url":"https://avatars.githubusercontent.com/u/18311922?s=40&v=4","login":"yzhang2016"},"buildBy":[{"avatar_url":"https://avatars.githubusercontent.com/u/18311922?s=40&v=4","login":"yzhang2016"},{"avatar_url":"https://avatars.githubusercontent.com/u/18735168?s=40&v=4","login":"scutpaul"},{"avatar_url":"https://avatars.githubusercontent.com/u/80380605?s=40&v=4","login":"YingqingHe"},{"avatar_url":"https://avatars.githubusercontent.com/u/4397546?s=40&v=4","login":"vinthony"},{"avatar_url":"https://avatars.githubusercontent.com/u/21290345?s=40&v=4","login":"MenghanXia"}]},{"full_name":"","description":"PyTorch Tutorial for Deep Learning Researchers","currentPeriodStars":385,"language":"Python","languageColor":"#3572A5","stargazers_count":28065,"forks_count":0,"owner":{"avatar_url":"https://avatars.githubusercontent.com/u/15663219?s=40&v=4","login":"yunjey"},"buildBy":[{"avatar_url":"https://avatars.githubusercontent.com/u/15663219?s=40&v=4","login":"yunjey"},{"avatar_url":"https://avatars.githubusercontent.com/u/1115503?s=40&v=4","login":"arisliang"},{"avatar_url":"https://avatars.githubusercontent.com/u/4231550?s=40&v=4","login":"JosephKJ"},{"avatar_url":"https://avatars.githubusercontent.com/u/901975?s=40&v=4","login":"hunkim"},{"avatar_url":"https://avatars.githubusercontent.com/u/4168984?s=40&v=4","login":"Kongsea"}]},{"full_name":"","description":"Skywork series models are pre-trained on 3.2TB of high-quality multilingual (mainly Chinese and English) and code data. We have open-sourced the model, training data, evaluation data, evaluation methods, etc. å¤©å·¥ç³»åˆ—æ¨¡å‹åœ¨3.2TBé«˜è´¨é‡å¤šè¯­è¨€å’Œä»£ç æ•°æ®ä¸Šè¿›è¡Œé¢„è®­ç»ƒã€‚æˆ‘ä»¬å¼€æºäº†æ¨¡å‹å‚æ•°ï¼Œè®­ç»ƒæ•°æ®ï¼Œè¯„ä¼°æ•°æ®ï¼Œè¯„ä¼°æ–¹æ³•ã€‚","currentPeriodStars":307,"language":"Python","languageColor":"#3572A5","stargazers_count":670,"forks_count":0,"owner":{"avatar_url":"https://avatars.githubusercontent.com/u/44833003?s=40&v=4","login":"zhao1iang"},"buildBy":[{"avatar_url":"https://avatars.githubusercontent.com/u/44833003?s=40&v=4","login":"zhao1iang"},{"avatar_url":"https://avatars.githubusercontent.com/u/35585791?s=40&v=4","login":"BBuf"},{"avatar_url":"https://avatars.githubusercontent.com/u/12186261?s=40&v=4","login":"chengtbf"},{"avatar_url":"https://avatars.githubusercontent.com/u/120169448?s=40&v=4","login":"SkyWorkAIGC"}]},{"full_name":"","description":"Single Image to 3D using Cross-Domain Diffusion","currentPeriodStars":627,"language":"Python","languageColor":"#3572A5","stargazers_count":2337,"forks_count":0,"owner":{"avatar_url":"https://avatars.githubusercontent.com/u/60975977?s=40&v=4","login":"xxlong0"},"buildBy":[{"avatar_url":"https://avatars.githubusercontent.com/u/60975977?s=40&v=4","login":"xxlong0"},{"avatar_url":"https://avatars.githubusercontent.com/u/17596726?s=40&v=4","login":"flamehaze1115"}]},{"full_name":"","description":"A list of useful payloads and bypass for Web Application Security and Pentest/CTF","currentPeriodStars":538,"language":"Python","languageColor":"#3572A5","stargazers_count":52437,"forks_count":0,"owner":{"avatar_url":"https://avatars.githubusercontent.com/u/12152583?s=40&v=4","login":"swisskyrepo"},"buildBy":[{"avatar_url":"https://avatars.githubusercontent.com/u/12152583?s=40&v=4","login":"swisskyrepo"},{"avatar_url":"https://avatars.githubusercontent.com/u/79218792?s=40&v=4","login":"p0dalirius"},{"avatar_url":"https://avatars.githubusercontent.com/u/16578570?s=40&v=4","login":"noraj"},{"avatar_url":"https://avatars.githubusercontent.com/u/25560738?s=40&v=4","login":"cyber-niz"}]},{"full_name":"","description":"This includes the original implementation of SELF-RAG: Learning to Retrieve, Generate and Critique through self-reflection by Akari Asai, Zeqiu Wu, Yizhong Wang, Avirup Sil, and Hannaneh Hajishirzi.","currentPeriodStars":158,"language":"Python","languageColor":"#3572A5","stargazers_count":501,"forks_count":0,"owner":{"avatar_url":"https://avatars.githubusercontent.com/u/16631193?s=40&v=4","login":"AkariAsai"},"buildBy":[{"avatar_url":"https://avatars.githubusercontent.com/u/16631193?s=40&v=4","login":"AkariAsai"},{"avatar_url":"https://avatars.githubusercontent.com/u/6923632?s=40&v=4","login":"shruti222patel"},{"avatar_url":"https://avatars.githubusercontent.com/u/68796651?s=40&v=4","login":"emrgnt-cmplxty"}]},{"full_name":"","description":"Bisheng is an open LLM devops platform for next generation AI applications.","currentPeriodStars":344,"language":"Python","languageColor":"#3572A5","stargazers_count":2269,"forks_count":0,"owner":{"avatar_url":"https://avatars.githubusercontent.com/u/3382757?s=40&v=4","login":"yaojin3616"},"buildBy":[{"avatar_url":"https://avatars.githubusercontent.com/u/3382757?s=40&v=4","login":"yaojin3616"},{"avatar_url":"https://avatars.githubusercontent.com/u/8371743?s=40&v=4","login":"dolphin0618"},{"avatar_url":"https://avatars.githubusercontent.com/u/2840346?s=40&v=4","login":"hrfng"},{"avatar_url":"https://avatars.githubusercontent.com/u/13868973?s=40&v=4","login":"gulixin0922"},{"avatar_url":"https://avatars.githubusercontent.com/u/9191067?s=40&v=4","login":"huangbaichao"}]},{"full_name":"","description":"OCRå›¾ç‰‡è½¬æ–‡å­—è¯†åˆ«è½¯ä»¶ï¼Œå®Œå…¨ç¦»çº¿ã€‚æˆªå±/æ‰¹é‡å¯¼å…¥å›¾ç‰‡ï¼Œæ”¯æŒå¤šå›½è¯­è¨€ã€åˆå¹¶æ®µè½ã€ç«–æ’æ–‡å­—ã€‚å¯æ’é™¤æ°´å°åŒºåŸŸï¼Œæå–å¹²å‡€çš„æ–‡æœ¬ã€‚åŸºäº PaddleOCR ã€‚","currentPeriodStars":2232,"language":"Python","languageColor":"#3572A5","stargazers_count":11985,"forks_count":0,"owner":{"avatar_url":"https://avatars.githubusercontent.com/u/56373419?s=40&v=4","login":"hiroi-sora"},"buildBy":[{"avatar_url":"https://avatars.githubusercontent.com/u/56373419?s=40&v=4","login":"hiroi-sora"},{"avatar_url":"https://avatars.githubusercontent.com/u/10486408?s=40&v=4","login":"KmBase"}]},{"full_name":"","description":"Robust Speech Recognition via Large-Scale Weak Supervision","currentPeriodStars":857,"language":"Python","languageColor":"#3572A5","stargazers_count":48149,"forks_count":0,"owner":{"avatar_url":"https://avatars.githubusercontent.com/u/266841?s=40&v=4","login":"jongwook"},"buildBy":[{"avatar_url":"https://avatars.githubusercontent.com/u/266841?s=40&v=4","login":"jongwook"},{"avatar_url":"https://avatars.githubusercontent.com/u/19899190?s=40&v=4","login":"ryanheise"},{"avatar_url":"https://avatars.githubusercontent.com/u/731031?s=40&v=4","login":"petterreinholdtsen"},{"avatar_url":"https://avatars.githubusercontent.com/u/1714412?s=40&v=4","login":"HennerM"},{"avatar_url":"https://avatars.githubusercontent.com/u/2590984?s=40&v=4","login":"VulumeCode"}]},{"full_name":"","description":"","currentPeriodStars":0,"stargazers_count":0,"forks_count":0,"owner":{},"buildBy":[]},{"full_name":"","description":"âš¡ Building applications with LLMs through composability âš¡","currentPeriodStars":1152,"language":"Python","languageColor":"#3572A5","stargazers_count":67558,"forks_count":0,"owner":{"avatar_url":"https://avatars.githubusercontent.com/u/11986836?s=40&v=4","login":"hwchase17"},"buildBy":[{"avatar_url":"https://avatars.githubusercontent.com/u/11986836?s=40&v=4","login":"hwchase17"},{"avatar_url":"https://avatars.githubusercontent.com/u/22008038?s=40&v=4","login":"baskaryan"},{"avatar_url":"https://avatars.githubusercontent.com/u/130488702?s=40&v=4","login":"dev2049"},{"avatar_url":"https://avatars.githubusercontent.com/u/56902?s=40&v=4","login":"nfcampos"},{"avatar_url":"https://avatars.githubusercontent.com/u/3205522?s=40&v=4","login":"eyurtsev"}]},{"full_name":"","description":"DeepSpeed is a deep learning optimization library that makes distributed training and inference easy, efficient, and effective.","currentPeriodStars":326,"language":"Python","languageColor":"#3572A5","stargazers_count":29426,"forks_count":0,"owner":{"avatar_url":"https://avatars.githubusercontent.com/u/645595?s=40&v=4","login":"jeffra"},"buildBy":[{"avatar_url":"https://avatars.githubusercontent.com/u/645595?s=40&v=4","login":"jeffra"},{"avatar_url":"https://avatars.githubusercontent.com/u/4271600?s=40&v=4","login":"tjruwase"},{"avatar_url":"https://avatars.githubusercontent.com/u/18311180?s=40&v=4","login":"mrwyattii"},{"avatar_url":"https://avatars.githubusercontent.com/u/620322?s=40&v=4","login":"ShadenSmith"},{"avatar_url":"https://avatars.githubusercontent.com/u/114770087?s=40&v=4","login":"loadams"}]},{"full_name":"","description":"Download market data from Yahoo! Finance's API","currentPeriodStars":90,"language":"Python","languageColor":"#3572A5","stargazers_count":10581,"forks_count":0,"owner":{"avatar_url":"https://avatars.githubusercontent.com/u/96923577?s=40&v=4","login":"ValueRaider"},"buildBy":[{"avatar_url":"https://avatars.githubusercontent.com/u/96923577?s=40&v=4","login":"ValueRaider"},{"avatar_url":"https://avatars.githubusercontent.com/u/1185458?s=40&v=4","login":"ranaroussi"},{"avatar_url":"https://avatars.githubusercontent.com/u/2439232?s=40&v=4","login":"fredrik-corneliusson"},{"avatar_url":"https://avatars.githubusercontent.com/u/55670941?s=40&v=4","login":"bradmetz"},{"avatar_url":"https://avatars.githubusercontent.com/u/25130636?s=40&v=4","login":"git-shogg"}]},{"full_name":"","description":"Easy-to-use LLM fine-tuning framework (LLaMA, BLOOM, Mistral, Baichuan, Qwen, ChatGLM)","currentPeriodStars":334,"language":"Python","languageColor":"#3572A5","stargazers_count":5971,"forks_count":0,"owner":{"avatar_url":"https://avatars.githubusercontent.com/u/16256802?s=40&v=4","login":"hiyouga"},"buildBy":[{"avatar_url":"https://avatars.githubusercontent.com/u/16256802?s=40&v=4","login":"hiyouga"},{"avatar_url":"https://avatars.githubusercontent.com/u/11713241?s=40&v=4","login":"codemayq"},{"avatar_url":"https://avatars.githubusercontent.com/u/64362896?s=40&v=4","login":"BUAADreamer"},{"avatar_url":"https://avatars.githubusercontent.com/u/52190211?s=40&v=4","login":"mMrBun"},{"avatar_url":"https://avatars.githubusercontent.com/u/17831637?s=40&v=4","login":"GitYCC"}]},{"full_name":"","description":"Faster Whisper transcription with CTranslate2","currentPeriodStars":158,"language":"Python","languageColor":"#3572A5","stargazers_count":5446,"forks_count":0,"owner":{"avatar_url":"https://avatars.githubusercontent.com/u/4805513?s=40&v=4","login":"guillaumekln"},"buildBy":[{"avatar_url":"https://avatars.githubusercontent.com/u/4805513?s=40&v=4","login":"guillaumekln"},{"avatar_url":"https://avatars.githubusercontent.com/u/98728125?s=40&v=4","login":"archive-r"},{"avatar_url":"https://avatars.githubusercontent.com/u/309265?s=40&v=4","login":"jordimas"},{"avatar_url":"https://avatars.githubusercontent.com/u/41221030?s=40&v=4","login":"FlippFuzz"},{"avatar_url":"https://avatars.githubusercontent.com/u/69023953?s=40&v=4","login":"Purfview"}]},{"full_name":"","description":"[SIGGRAPH Asia 2022] VideoReTalking: Audio-based Lip Synchronization for Talking Head Video Editing In the Wild","currentPeriodStars":430,"language":"Python","languageColor":"#3572A5","stargazers_count":3288,"forks_count":0,"owner":{"avatar_url":"https://avatars.githubusercontent.com/u/4397546?s=40&v=4","login":"vinthony"},"buildBy":[{"avatar_url":"https://avatars.githubusercontent.com/u/4397546?s=40&v=4","login":"vinthony"},{"avatar_url":"https://avatars.githubusercontent.com/u/113667477?s=40&v=4","login":"kunncheng"},{"avatar_url":"https://avatars.githubusercontent.com/u/148847552?s=40&v=4","login":"hairyputtar"},{"avatar_url":"https://avatars.githubusercontent.com/u/25414059?s=40&v=4","login":"steven12138"},{"avatar_url":"https://avatars.githubusercontent.com/u/70536672?s=40&v=4","login":"chenxwh"}]},{"full_name":"","description":"Code and models for NExT-GPT: Any-to-Any Multimodal Large Language Model","currentPeriodStars":96,"language":"Python","languageColor":"#3572A5","stargazers_count":2313,"forks_count":0,"owner":{"avatar_url":"https://avatars.githubusercontent.com/u/22408252?s=40&v=4","login":"ChocoWu"},"buildBy":[{"avatar_url":"https://avatars.githubusercontent.com/u/22408252?s=40&v=4","login":"ChocoWu"},{"avatar_url":"https://avatars.githubusercontent.com/u/18722770?s=40&v=4","login":"scofield7419"},{"avatar_url":"https://avatars.githubusercontent.com/u/22633385?s=40&v=4","login":"eltociear"},{"avatar_url":"https://avatars.githubusercontent.com/u/143576855?s=40&v=4","login":"NExT-GPT"}]},{"full_name":"","description":"A Gradio web UI for Large Language Models. Supports transformers, GPTQ, AWQ, EXL2, llama.cpp (GGUF), Llama models.","currentPeriodStars":442,"language":"Python","languageColor":"#3572A5","stargazers_count":26531,"forks_count":0,"owner":{"avatar_url":"https://avatars.githubusercontent.com/u/112222186?s=40&v=4","login":"oobabooga"},"buildBy":[{"avatar_url":"https://avatars.githubusercontent.com/u/112222186?s=40&v=4","login":"oobabooga"},{"avatar_url":"https://avatars.githubusercontent.com/u/3887729?s=40&v=4","login":"jllllll"},{"avatar_url":"https://avatars.githubusercontent.com/u/4000772?s=40&v=4","login":"mcmonkey4eva"},{"avatar_url":"https://avatars.githubusercontent.com/u/73265741?s=40&v=4","login":"matatonic"},{"avatar_url":"https://avatars.githubusercontent.com/in/29110?s=40&v=4","login":"dependabot"}]},{"full_name":"","description":"Composable transformations of Python+NumPy programs: differentiate, vectorize, JIT to GPU/TPU, and more","currentPeriodStars":281,"language":"Python","languageColor":"#3572A5","stargazers_count":25444,"forks_count":0,"owner":{"avatar_url":"https://avatars.githubusercontent.com/u/348932?s=40&v=4","login":"hawkinsp"},"buildBy":[{"avatar_url":"https://avatars.githubusercontent.com/u/348932?s=40&v=4","login":"hawkinsp"},{"avatar_url":"https://avatars.githubusercontent.com/u/1458824?s=40&v=4","login":"mattjj"},{"avatar_url":"https://avatars.githubusercontent.com/u/781659?s=40&v=4","login":"jakevdp"},{"avatar_url":"https://avatars.githubusercontent.com/u/3890983?s=40&v=4","login":"gnecula"}]},{"full_name":"","description":"ğŸ¤— Transformers: State-of-the-art Machine Learning for Pytorch, TensorFlow, and JAX.","currentPeriodStars":627,"language":"Python","languageColor":"#3572A5","stargazers_count":114830,"forks_count":0,"owner":{"avatar_url":"https://avatars.githubusercontent.com/u/35901082?s=40&v=4","login":"sgugger"},"buildBy":[{"avatar_url":"https://avatars.githubusercontent.com/u/35901082?s=40&v=4","login":"sgugger"},{"avatar_url":"https://avatars.githubusercontent.com/u/7353373?s=40&v=4","login":"thomwolf"},{"avatar_url":"https://avatars.githubusercontent.com/u/30755778?s=40&v=4","login":"LysandreJik"},{"avatar_url":"https://avatars.githubusercontent.com/u/23423619?s=40&v=4","login":"patrickvonplaten"},{"avatar_url":"https://avatars.githubusercontent.com/u/2521628?s=40&v=4","login":"ydshieh"}]},{"full_name":"","description":"My Python Examples","currentPeriodStars":62,"language":"Python","languageColor":"#3572A5","stargazers_count":28618,"forks_count":0,"owner":{"avatar_url":"https://avatars.githubusercontent.com/u/1170130?s=40&v=4","login":"geekcomputers"},"buildBy":[{"avatar_url":"https://avatars.githubusercontent.com/u/1170130?s=40&v=4","login":"geekcomputers"},{"avatar_url":"https://avatars.githubusercontent.com/u/112542130?s=40&v=4","login":"sayampradhan"},{"avatar_url":"https://avatars.githubusercontent.com/in/29110?s=40&v=4","login":"dependabot"},{"avatar_url":"https://avatars.githubusercontent.com/u/83634399?s=40&v=4","login":"cyai"},{"avatar_url":"https://avatars.githubusercontent.com/u/3709715?s=40&v=4","login":"cclauss"}]},{"full_name":"","description":"LLM App is a production framework for building and serving AI applications and LLM-enabled real-time data pipelines.","currentPeriodStars":152,"language":"Python","languageColor":"#3572A5","stargazers_count":930,"forks_count":0,"owner":{"avatar_url":"https://avatars.githubusercontent.com/u/123164531?s=40&v=4","login":"mdmalhou"},"buildBy":[{"avatar_url":"https://avatars.githubusercontent.com/u/123164531?s=40&v=4","login":"mdmalhou"},{"avatar_url":"https://avatars.githubusercontent.com/u/106311100?s=40&v=4","login":"pw-ppodhajski"},{"avatar_url":"https://avatars.githubusercontent.com/u/15914792?s=40&v=4","login":"dxtrous"},{"avatar_url":"https://avatars.githubusercontent.com/u/14247607?s=40&v=4","login":"Boburmirzo"},{"avatar_url":"https://avatars.githubusercontent.com/u/32928185?s=40&v=4","login":"KamilPiechowiak"}]},{"full_name":"","description":"ChatGLM-6B: An Open Bilingual Dialogue Language Model | å¼€æºåŒè¯­å¯¹è¯è¯­è¨€æ¨¡å‹","currentPeriodStars":247,"language":"Python","languageColor":"#3572A5","stargazers_count":35441,"forks_count":0,"owner":{"avatar_url":"https://avatars.githubusercontent.com/u/28836239?s=40&v=4","login":"duzx16"},"buildBy":[{"avatar_url":"https://avatars.githubusercontent.com/u/28836239?s=40&v=4","login":"duzx16"},{"avatar_url":"https://avatars.githubusercontent.com/u/19250540?s=40&v=4","login":"rainatam"},{"avatar_url":"https://avatars.githubusercontent.com/u/35831349?s=40&v=4","login":"Xiao9905"},{"avatar_url":"https://avatars.githubusercontent.com/u/11155657?s=40&v=4","login":"Sengxian"},{"avatar_url":"https://avatars.githubusercontent.com/u/33094695?s=40&v=4","login":"Cherrysaber"}]},{"full_name":"","description":"Inference code for LLaMA models","currentPeriodStars":499,"language":"Python","languageColor":"#3572A5","stargazers_count":44829,"forks_count":0,"owner":{"avatar_url":"https://avatars.githubusercontent.com/u/11398925?s=40&v=4","login":"jspisak"},"buildBy":[{"avatar_url":"https://avatars.githubusercontent.com/u/11398925?s=40&v=4","login":"jspisak"},{"avatar_url":"https://avatars.githubusercontent.com/u/4998695?s=40&v=4","login":"timlacroix"},{"avatar_url":"https://avatars.githubusercontent.com/u/2332808?s=40&v=4","login":"ruanslv"},{"avatar_url":"https://avatars.githubusercontent.com/u/127536312?s=40&v=4","login":"sekyondaMeta"},{"avatar_url":"https://avatars.githubusercontent.com/u/97736191?s=40&v=4","login":"AurRod"}]}]}
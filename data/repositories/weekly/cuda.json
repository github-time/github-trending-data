{"updateTime":"2024-02-06 02:20:20","data":[{"full_name":"","description":"Instant neural graphics primitives: lightning fast NeRF and more","currentPeriodStars":69,"language":"Cuda","languageColor":"#3A4E3A","stargazers_count":14906,"forks_count":0,"owner":{"avatar_url":"https://avatars.githubusercontent.com/u/4923655?s=40&v=4","login":"Tom94"},"buildBy":[{"avatar_url":"https://avatars.githubusercontent.com/u/4923655?s=40&v=4","login":"Tom94"},{"avatar_url":"https://avatars.githubusercontent.com/u/7601391?s=40&v=4","login":"FlorisE"},{"avatar_url":"https://avatars.githubusercontent.com/u/29726242?s=40&v=4","login":"jc211"},{"avatar_url":"https://avatars.githubusercontent.com/u/7057863?s=40&v=4","login":"yenchenlin"},{"avatar_url":"https://avatars.githubusercontent.com/u/3280839?s=40&v=4","login":"JamesPerlman"}]},{"full_name":"","description":"CUDA accelerated rasterization of gaussian splatting","currentPeriodStars":28,"language":"Cuda","languageColor":"#3A4E3A","stargazers_count":587,"forks_count":0,"owner":{"avatar_url":"https://avatars.githubusercontent.com/u/5694811?s=40&v=4","login":"vye16"},"buildBy":[{"avatar_url":"https://avatars.githubusercontent.com/u/5694811?s=40&v=4","login":"vye16"},{"avatar_url":"https://avatars.githubusercontent.com/u/10151885?s=40&v=4","login":"liruilong940607"},{"avatar_url":"https://avatars.githubusercontent.com/u/30566358?s=40&v=4","login":"maturk"},{"avatar_url":"https://avatars.githubusercontent.com/u/102644383?s=40&v=4","login":"Zhuoyang-Pan"},{"avatar_url":"https://avatars.githubusercontent.com/u/15806475?s=40&v=4","login":"kerrj"}]},{"full_name":"","description":"","currentPeriodStars":0,"stargazers_count":0,"forks_count":0,"owner":{},"buildBy":[]},{"full_name":"","description":"FlashInfer: Kernel Library for LLM Serving","currentPeriodStars":20,"language":"Cuda","languageColor":"#3A4E3A","stargazers_count":202,"forks_count":0,"owner":{"avatar_url":"https://avatars.githubusercontent.com/u/11773619?s=40&v=4","login":"yzh119"},"buildBy":[{"avatar_url":"https://avatars.githubusercontent.com/u/11773619?s=40&v=4","login":"yzh119"},{"avatar_url":"https://avatars.githubusercontent.com/u/45167100?s=40&v=4","login":"MasterJH5574"},{"avatar_url":"https://avatars.githubusercontent.com/u/2470081?s=40&v=4","login":"abcdabcd987"},{"avatar_url":"https://avatars.githubusercontent.com/u/22515877?s=40&v=4","login":"junrushao"},{"avatar_url":"https://avatars.githubusercontent.com/u/16838183?s=40&v=4","login":"cyx-6"}]},{"full_name":"","description":"NCCL Tests","currentPeriodStars":5,"language":"Cuda","languageColor":"#3A4E3A","stargazers_count":602,"forks_count":0,"owner":{"avatar_url":"https://avatars.githubusercontent.com/u/2538330?s=40&v=4","login":"AddyLaddy"},"buildBy":[{"avatar_url":"https://avatars.githubusercontent.com/u/2538330?s=40&v=4","login":"AddyLaddy"},{"avatar_url":"https://avatars.githubusercontent.com/u/12857445?s=40&v=4","login":"sjeaugey"},{"avatar_url":"https://avatars.githubusercontent.com/u/687269?s=40&v=4","login":"lukeyeager"},{"avatar_url":"https://avatars.githubusercontent.com/u/2293859?s=40&v=4","login":"jbachan"},{"avatar_url":"https://avatars.githubusercontent.com/u/6690627?s=40&v=4","login":"jithinjosepkl"}]},{"full_name":"","description":"üéâCUDA Á¨îËÆ∞ / È´òÈ¢ëÈù¢ËØïÈ¢òÊ±áÊÄª / C++Á¨îËÆ∞Ôºå‰∏™‰∫∫Á¨îËÆ∞ÔºåÊõ¥Êñ∞ÈöèÁºò: sgemm„ÄÅsgemv„ÄÅwarp reduce„ÄÅblock reduce„ÄÅdot product„ÄÅelementwise„ÄÅsoftmax„ÄÅlayernorm„ÄÅrmsnorm„ÄÅhist etc.","currentPeriodStars":31,"language":"Cuda","languageColor":"#3A4E3A","stargazers_count":120,"forks_count":0,"owner":{"avatar_url":"https://avatars.githubusercontent.com/u/31974251?s=40&v=4","login":"DefTruth"},"buildBy":[{"avatar_url":"https://avatars.githubusercontent.com/u/31974251?s=40&v=4","login":"DefTruth"}]},{"full_name":"","description":"This is a series of GPU optimization topics. Here we will introduce how to optimize the CUDA kernel in detail. I will introduce several basic kernel optimizations, including: elementwise, reduce, sgemv, sgemm, etc. The performance of these kernels is basically at or near the theoretical limit.","currentPeriodStars":16,"language":"Cuda","languageColor":"#3A4E3A","stargazers_count":583,"forks_count":0,"owner":{"avatar_url":"https://avatars.githubusercontent.com/u/85323580?s=40&v=4","login":"Liu-xiandong"},"buildBy":[{"avatar_url":"https://avatars.githubusercontent.com/u/85323580?s=40&v=4","login":"Liu-xiandong"},{"avatar_url":"https://avatars.githubusercontent.com/u/63796752?s=40&v=4","login":"ZhangGe6"}]},{"full_name":"","description":"cuGraph - RAPIDS Graph Analytics Library","currentPeriodStars":8,"language":"Cuda","languageColor":"#3A4E3A","stargazers_count":1503,"forks_count":0,"owner":{"avatar_url":"https://avatars.githubusercontent.com/u/34135411?s=40&v=4","login":"BradReesWork"},"buildBy":[{"avatar_url":"https://avatars.githubusercontent.com/u/34135411?s=40&v=4","login":"BradReesWork"},{"avatar_url":"https://avatars.githubusercontent.com/u/45606510?s=40&v=4","login":"afender"},{"avatar_url":"https://avatars.githubusercontent.com/u/45857425?s=40&v=4","login":"seunghwak"},{"avatar_url":"https://avatars.githubusercontent.com/u/45364586?s=40&v=4","login":"ChuckHastings"},{"avatar_url":"https://avatars.githubusercontent.com/u/41401566?s=40&v=4","login":"Iroy30"}]},{"full_name":"","description":"CUDA Library Samples","currentPeriodStars":12,"language":"Cuda","languageColor":"#3A4E3A","stargazers_count":1079,"forks_count":0,"owner":{"avatar_url":"https://avatars.githubusercontent.com/u/50021634?s=40&v=4","login":"mnicely"},"buildBy":[{"avatar_url":"https://avatars.githubusercontent.com/u/50021634?s=40&v=4","login":"mnicely"},{"avatar_url":"https://avatars.githubusercontent.com/u/50413820?s=40&v=4","login":"fbusato"},{"avatar_url":"https://avatars.githubusercontent.com/u/5178240?s=40&v=4","login":"springer13"},{"avatar_url":"https://avatars.githubusercontent.com/u/20576829?s=40&v=4","login":"almogsegal"},{"avatar_url":"https://avatars.githubusercontent.com/u/1217114?s=40&v=4","login":"llukas"}]},{"full_name":"","description":"Causal depthwise conv1d in CUDA, with a PyTorch interface","currentPeriodStars":8,"language":"Cuda","languageColor":"#3A4E3A","stargazers_count":77,"forks_count":0,"owner":{"avatar_url":"https://avatars.githubusercontent.com/u/5616128?s=40&v=4","login":"tridao"},"buildBy":[{"avatar_url":"https://avatars.githubusercontent.com/u/5616128?s=40&v=4","login":"tridao"},{"avatar_url":"https://avatars.githubusercontent.com/u/9017200?s=40&v=4","login":"havietisov"},{"avatar_url":"https://avatars.githubusercontent.com/u/44860323?s=40&v=4","login":"Wongboo"}]},{"full_name":"","description":"","currentPeriodStars":0,"stargazers_count":0,"forks_count":0,"owner":{},"buildBy":[]},{"full_name":"","description":"","currentPeriodStars":0,"stargazers_count":0,"forks_count":0,"owner":{},"buildBy":[]},{"full_name":"","description":"RAFT contains fundamental widely-used algorithms and primitives for machine learning and information retrieval. The algorithms are CUDA-accelerated and form building blocks for more easily writing high performance applications.","currentPeriodStars":4,"language":"Cuda","languageColor":"#3A4E3A","stargazers_count":538,"forks_count":0,"owner":{"avatar_url":"https://avatars.githubusercontent.com/u/1242464?s=40&v=4","login":"cjnolet"},"buildBy":[{"avatar_url":"https://avatars.githubusercontent.com/u/1242464?s=40&v=4","login":"cjnolet"},{"avatar_url":"https://avatars.githubusercontent.com/u/38199262?s=40&v=4","login":"GPUtester"},{"avatar_url":"https://avatars.githubusercontent.com/u/37386037?s=40&v=4","login":"aschaffer"},{"avatar_url":"https://avatars.githubusercontent.com/u/14876585?s=40&v=4","login":"divyegala"},{"avatar_url":"https://avatars.githubusercontent.com/u/9253178?s=40&v=4","login":"achirkin"}]},{"full_name":"","description":"","currentPeriodStars":0,"stargazers_count":0,"forks_count":0,"owner":{},"buildBy":[]}]}
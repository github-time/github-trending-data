{"updateTime":"2025-08-21 02:32:15","data":[{"full_name":"","description":"FlashInfer: Kernel Library for LLM Serving","currentPeriodStars":63,"language":"Cuda","languageColor":"#3A4E3A","stargazers_count":3598,"forks_count":0,"owner":{"avatar_url":"https://avatars.githubusercontent.com/u/11773619?s=40&v=4","login":"yzh119"},"buildBy":[{"avatar_url":"https://avatars.githubusercontent.com/u/11773619?s=40&v=4","login":"yzh119"},{"avatar_url":"https://avatars.githubusercontent.com/u/2470081?s=40&v=4","login":"abcdabcd987"},{"avatar_url":"https://avatars.githubusercontent.com/u/52445717?s=40&v=4","login":"yyihuang"},{"avatar_url":"https://avatars.githubusercontent.com/u/46627482?s=40&v=4","login":"zhyncs"},{"avatar_url":"https://avatars.githubusercontent.com/u/45167100?s=40&v=4","login":"MasterJH5574"}]},{"full_name":"","description":"Quantized Attention achieves speedup of 2-5x and 3-11x compared to FlashAttention and xformers, without lossing end-to-end metrics across language, image, and video models.","currentPeriodStars":45,"language":"Cuda","languageColor":"#3A4E3A","stargazers_count":2243,"forks_count":0,"owner":{"avatar_url":"https://avatars.githubusercontent.com/u/59364182?s=40&v=4","login":"jt-zhang"},"buildBy":[{"avatar_url":"https://avatars.githubusercontent.com/u/59364182?s=40&v=4","login":"jt-zhang"},{"avatar_url":"https://avatars.githubusercontent.com/u/110245937?s=40&v=4","login":"jason-huang03"},{"avatar_url":"https://avatars.githubusercontent.com/u/37583905?s=40&v=4","login":"XiaomingXu1995"},{"avatar_url":"https://avatars.githubusercontent.com/u/38180676?s=40&v=4","login":"whx1003"},{"avatar_url":"https://avatars.githubusercontent.com/u/162807153?s=40&v=4","login":"BobQC"}]},{"full_name":"","description":"CUDA accelerated rasterization of gaussian splatting","currentPeriodStars":29,"language":"Cuda","languageColor":"#3A4E3A","stargazers_count":3453,"forks_count":0,"owner":{"avatar_url":"https://avatars.githubusercontent.com/u/10151885?s=40&v=4","login":"liruilong940607"},"buildBy":[{"avatar_url":"https://avatars.githubusercontent.com/u/10151885?s=40&v=4","login":"liruilong940607"},{"avatar_url":"https://avatars.githubusercontent.com/u/5694811?s=40&v=4","login":"vye16"},{"avatar_url":"https://avatars.githubusercontent.com/u/30566358?s=40&v=4","login":"maturk"},{"avatar_url":"https://avatars.githubusercontent.com/u/15806475?s=40&v=4","login":"kerrj"},{"avatar_url":"https://avatars.githubusercontent.com/u/6992947?s=40&v=4","login":"brentyi"}]},{"full_name":"","description":"LLM training in simple, raw C/CUDA","currentPeriodStars":67,"language":"Cuda","languageColor":"#3A4E3A","stargazers_count":27423,"forks_count":0,"owner":{"avatar_url":"https://avatars.githubusercontent.com/u/241138?s=40&v=4","login":"karpathy"},"buildBy":[{"avatar_url":"https://avatars.githubusercontent.com/u/241138?s=40&v=4","login":"karpathy"},{"avatar_url":"https://avatars.githubusercontent.com/u/7938269?s=40&v=4","login":"ngc92"},{"avatar_url":"https://avatars.githubusercontent.com/u/29271842?s=40&v=4","login":"gordicaleksa"},{"avatar_url":"https://avatars.githubusercontent.com/u/7082233?s=40&v=4","login":"ademeure"},{"avatar_url":"https://avatars.githubusercontent.com/u/55313766?s=40&v=4","login":"rosslwheeler"}]},{"full_name":"","description":"GPU accelerated decision optimization","currentPeriodStars":16,"language":"Cuda","languageColor":"#3A4E3A","stargazers_count":377,"forks_count":0,"owner":{"avatar_url":"https://avatars.githubusercontent.com/u/42624703?s=40&v=4","login":"rgsl888prabhu"},"buildBy":[{"avatar_url":"https://avatars.githubusercontent.com/u/42624703?s=40&v=4","login":"rgsl888prabhu"},{"avatar_url":"https://avatars.githubusercontent.com/u/184431765?s=40&v=4","login":"chris-maes"},{"avatar_url":"https://avatars.githubusercontent.com/u/6844564?s=40&v=4","login":"rg20"},{"avatar_url":"https://avatars.githubusercontent.com/u/160623740?s=40&v=4","login":"aliceb-nv"},{"avatar_url":"https://avatars.githubusercontent.com/u/12140289?s=40&v=4","login":"akifcorduk"}]},{"full_name":"","description":"DeepEP: an efficient expert-parallel communication library","currentPeriodStars":39,"language":"Cuda","languageColor":"#3A4E3A","stargazers_count":8417,"forks_count":0,"owner":{"avatar_url":"https://avatars.githubusercontent.com/u/35299455?s=40&v=4","login":"LyricZhao"},"buildBy":[{"avatar_url":"https://avatars.githubusercontent.com/u/35299455?s=40&v=4","login":"LyricZhao"},{"avatar_url":"https://avatars.githubusercontent.com/u/9213347?s=40&v=4","login":"sphish"},{"avatar_url":"https://avatars.githubusercontent.com/u/5236035?s=40&v=4","login":"fzyzcjy"},{"avatar_url":"https://avatars.githubusercontent.com/u/166747556?s=40&v=4","login":"seth-howell"},{"avatar_url":"https://avatars.githubusercontent.com/u/23236638?s=40&v=4","login":"youkaichao"}]},{"full_name":"","description":"DeepGEMM: clean and efficient FP8 GEMM kernels with fine-grained scaling","currentPeriodStars":25,"language":"Cuda","languageColor":"#3A4E3A","stargazers_count":5617,"forks_count":0,"owner":{"avatar_url":"https://avatars.githubusercontent.com/u/35299455?s=40&v=4","login":"LyricZhao"},"buildBy":[{"avatar_url":"https://avatars.githubusercontent.com/u/35299455?s=40&v=4","login":"LyricZhao"},{"avatar_url":"https://avatars.githubusercontent.com/u/44948473?s=40&v=4","login":"soundOfDestiny"},{"avatar_url":"https://avatars.githubusercontent.com/u/94977922?s=40&v=4","login":"zheanxu"},{"avatar_url":"https://avatars.githubusercontent.com/u/34201481?s=40&v=4","login":"RayWang96"},{"avatar_url":"https://avatars.githubusercontent.com/u/49888860?s=40&v=4","login":"sazczmh"}]},{"full_name":"","description":"","currentPeriodStars":0,"stargazers_count":0,"forks_count":0,"owner":{},"buildBy":[]},{"full_name":"","description":"CUDA Library Samples","currentPeriodStars":10,"language":"Cuda","languageColor":"#3A4E3A","stargazers_count":2065,"forks_count":0,"owner":{"avatar_url":"https://avatars.githubusercontent.com/u/50021634?s=40&v=4","login":"mnicely"},"buildBy":[{"avatar_url":"https://avatars.githubusercontent.com/u/50021634?s=40&v=4","login":"mnicely"},{"avatar_url":"https://avatars.githubusercontent.com/u/50413820?s=40&v=4","login":"fbusato"},{"avatar_url":"https://avatars.githubusercontent.com/u/20576829?s=40&v=4","login":"almogsegal"},{"avatar_url":"https://avatars.githubusercontent.com/u/15225631?s=40&v=4","login":"rsdubtso"},{"avatar_url":"https://avatars.githubusercontent.com/u/1907101?s=40&v=4","login":"mrogowski"}]},{"full_name":"","description":"Tile primitives for speedy kernels","currentPeriodStars":18,"language":"Cuda","languageColor":"#3A4E3A","stargazers_count":2601,"forks_count":0,"owner":{"avatar_url":"https://avatars.githubusercontent.com/u/11230781?s=40&v=4","login":"benjaminfspector"},"buildBy":[{"avatar_url":"https://avatars.githubusercontent.com/u/11230781?s=40&v=4","login":"benjaminfspector"},{"avatar_url":"https://avatars.githubusercontent.com/u/48185825?s=40&v=4","login":"Aaryan0404"},{"avatar_url":"https://avatars.githubusercontent.com/u/29069240?s=40&v=4","login":"simran-arora"},{"avatar_url":"https://avatars.githubusercontent.com/u/31910389?s=40&v=4","login":"StuartSul"},{"avatar_url":"https://avatars.githubusercontent.com/u/72822184?s=40&v=4","login":"dylanllim"}]},{"full_name":"","description":"Causal depthwise conv1d in CUDA, with a PyTorch interface","currentPeriodStars":7,"language":"Cuda","languageColor":"#3A4E3A","stargazers_count":549,"forks_count":0,"owner":{"avatar_url":"https://avatars.githubusercontent.com/u/5616128?s=40&v=4","login":"tridao"},"buildBy":[{"avatar_url":"https://avatars.githubusercontent.com/u/5616128?s=40&v=4","login":"tridao"},{"avatar_url":"https://avatars.githubusercontent.com/u/164261418?s=40&v=4","login":"ajassani"},{"avatar_url":"https://avatars.githubusercontent.com/u/32954280?s=40&v=4","login":"mayank31398"},{"avatar_url":"https://avatars.githubusercontent.com/u/22727137?s=40&v=4","login":"johnnynunez"},{"avatar_url":"https://avatars.githubusercontent.com/u/158011354?s=40&v=4","login":"amoskvic"}]},{"full_name":"","description":"[ARCHIVED] Cooperative primitives for CUDA C++. See https://github.com/NVIDIA/cccl","currentPeriodStars":3,"language":"Cuda","languageColor":"#3A4E3A","stargazers_count":1775,"forks_count":0,"owner":{"avatar_url":"https://avatars.githubusercontent.com/u/9890394?s=40&v=4","login":"gevtushenko"},"buildBy":[{"avatar_url":"https://avatars.githubusercontent.com/u/9890394?s=40&v=4","login":"gevtushenko"},{"avatar_url":"https://avatars.githubusercontent.com/u/58744?s=40&v=4","login":"alliepiper"},{"avatar_url":"https://avatars.githubusercontent.com/u/1476032?s=40&v=4","login":"dumerrill"},{"avatar_url":"https://avatars.githubusercontent.com/u/398194?s=40&v=4","login":"brycelelbach"},{"avatar_url":"https://avatars.githubusercontent.com/u/3958403?s=40&v=4","login":"elstehle"}]},{"full_name":"","description":"NCCL Tests","currentPeriodStars":6,"language":"Cuda","languageColor":"#3A4E3A","stargazers_count":1223,"forks_count":0,"owner":{"avatar_url":"https://avatars.githubusercontent.com/u/2538330?s=40&v=4","login":"AddyLaddy"},"buildBy":[{"avatar_url":"https://avatars.githubusercontent.com/u/2538330?s=40&v=4","login":"AddyLaddy"},{"avatar_url":"https://avatars.githubusercontent.com/u/12857445?s=40&v=4","login":"sjeaugey"},{"avatar_url":"https://avatars.githubusercontent.com/u/2293859?s=40&v=4","login":"jbachan"},{"avatar_url":"https://avatars.githubusercontent.com/u/687269?s=40&v=4","login":"lukeyeager"},{"avatar_url":"https://avatars.githubusercontent.com/u/6690627?s=40&v=4","login":"jithinjosepkl"}]},{"full_name":"","description":"","currentPeriodStars":0,"stargazers_count":0,"forks_count":0,"owner":{},"buildBy":[]},{"full_name":"","description":"CUDA Kernel Benchmarking Library","currentPeriodStars":3,"language":"Cuda","languageColor":"#3A4E3A","stargazers_count":701,"forks_count":0,"owner":{"avatar_url":"https://avatars.githubusercontent.com/u/58744?s=40&v=4","login":"alliepiper"},"buildBy":[{"avatar_url":"https://avatars.githubusercontent.com/u/58744?s=40&v=4","login":"alliepiper"},{"avatar_url":"https://avatars.githubusercontent.com/u/21087696?s=40&v=4","login":"oleksandr-pavlyk"},{"avatar_url":"https://avatars.githubusercontent.com/u/9890394?s=40&v=4","login":"gevtushenko"},{"avatar_url":"https://avatars.githubusercontent.com/u/215756?s=40&v=4","login":"robertmaynard"},{"avatar_url":"https://avatars.githubusercontent.com/u/12716979?s=40&v=4","login":"PointKernel"}]},{"full_name":"","description":"SpargeAttention: A training-free sparse attention that can accelerate any model inference.","currentPeriodStars":8,"language":"Cuda","languageColor":"#3A4E3A","stargazers_count":685,"forks_count":0,"owner":{"avatar_url":"https://avatars.githubusercontent.com/u/59364182?s=40&v=4","login":"jt-zhang"},"buildBy":[{"avatar_url":"https://avatars.githubusercontent.com/u/59364182?s=40&v=4","login":"jt-zhang"},{"avatar_url":"https://avatars.githubusercontent.com/u/66510463?s=40&v=4","login":"Xiang-cd"},{"avatar_url":"https://avatars.githubusercontent.com/u/110245937?s=40&v=4","login":"jason-huang03"},{"avatar_url":"https://avatars.githubusercontent.com/u/37583905?s=40&v=4","login":"XiaomingXu1995"},{"avatar_url":"https://avatars.githubusercontent.com/u/564322?s=40&v=4","login":"tokoro10g"}]},{"full_name":"","description":"A massively parallel, optimal functional runtime in Rust","currentPeriodStars":8,"language":"Cuda","languageColor":"#3A4E3A","stargazers_count":11090,"forks_count":0,"owner":{"avatar_url":"https://avatars.githubusercontent.com/u/13090166?s=40&v=4","login":"VictorTaelin"},"buildBy":[{"avatar_url":"https://avatars.githubusercontent.com/u/13090166?s=40&v=4","login":"VictorTaelin"},{"avatar_url":"https://avatars.githubusercontent.com/u/5505315?s=40&v=4","login":"enricozb"},{"avatar_url":"https://avatars.githubusercontent.com/u/53550620?s=40&v=4","login":"kings177"},{"avatar_url":"https://avatars.githubusercontent.com/u/30930225?s=40&v=4","login":"edusporto"},{"avatar_url":"https://avatars.githubusercontent.com/u/44031566?s=40&v=4","login":"tjjfvi"}]}]}
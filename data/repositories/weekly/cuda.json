{"updateTime":"2025-01-12 02:24:46","data":[{"full_name":"","description":"FlashInfer: Kernel Library for LLM Serving","currentPeriodStars":79,"language":"Cuda","languageColor":"#3A4E3A","stargazers_count":1758,"forks_count":0,"owner":{"avatar_url":"https://avatars.githubusercontent.com/u/11773619?s=40&v=4","login":"yzh119"},"buildBy":[{"avatar_url":"https://avatars.githubusercontent.com/u/11773619?s=40&v=4","login":"yzh119"},{"avatar_url":"https://avatars.githubusercontent.com/u/2470081?s=40&v=4","login":"abcdabcd987"},{"avatar_url":"https://avatars.githubusercontent.com/u/45167100?s=40&v=4","login":"MasterJH5574"},{"avatar_url":"https://avatars.githubusercontent.com/u/46627482?s=40&v=4","login":"zhyncs"},{"avatar_url":"https://avatars.githubusercontent.com/in/15368?s=40&v=4","login":"github-actions"}]},{"full_name":"","description":"LLM training in simple, raw C/CUDA","currentPeriodStars":88,"language":"Cuda","languageColor":"#3A4E3A","stargazers_count":25002,"forks_count":0,"owner":{"avatar_url":"https://avatars.githubusercontent.com/u/241138?s=40&v=4","login":"karpathy"},"buildBy":[{"avatar_url":"https://avatars.githubusercontent.com/u/241138?s=40&v=4","login":"karpathy"},{"avatar_url":"https://avatars.githubusercontent.com/u/7938269?s=40&v=4","login":"ngc92"},{"avatar_url":"https://avatars.githubusercontent.com/u/29271842?s=40&v=4","login":"gordicaleksa"},{"avatar_url":"https://avatars.githubusercontent.com/u/7082233?s=40&v=4","login":"ademeure"},{"avatar_url":"https://avatars.githubusercontent.com/u/55313766?s=40&v=4","login":"rosslwheeler"}]},{"full_name":"","description":"Instant neural graphics primitives: lightning fast NeRF and more","currentPeriodStars":32,"language":"Cuda","languageColor":"#3A4E3A","stargazers_count":16179,"forks_count":0,"owner":{"avatar_url":"https://avatars.githubusercontent.com/u/4923655?s=40&v=4","login":"Tom94"},"buildBy":[{"avatar_url":"https://avatars.githubusercontent.com/u/4923655?s=40&v=4","login":"Tom94"},{"avatar_url":"https://avatars.githubusercontent.com/u/7601391?s=40&v=4","login":"FlorisE"},{"avatar_url":"https://avatars.githubusercontent.com/u/29726242?s=40&v=4","login":"jc211"},{"avatar_url":"https://avatars.githubusercontent.com/u/7057863?s=40&v=4","login":"yenchenlin"},{"avatar_url":"https://avatars.githubusercontent.com/u/3280839?s=40&v=4","login":"JamesPerlman"}]},{"full_name":"","description":"NCCL Tests","currentPeriodStars":9,"language":"Cuda","languageColor":"#3A4E3A","stargazers_count":960,"forks_count":0,"owner":{"avatar_url":"https://avatars.githubusercontent.com/u/2538330?s=40&v=4","login":"AddyLaddy"},"buildBy":[{"avatar_url":"https://avatars.githubusercontent.com/u/2538330?s=40&v=4","login":"AddyLaddy"},{"avatar_url":"https://avatars.githubusercontent.com/u/12857445?s=40&v=4","login":"sjeaugey"},{"avatar_url":"https://avatars.githubusercontent.com/u/2293859?s=40&v=4","login":"jbachan"},{"avatar_url":"https://avatars.githubusercontent.com/u/687269?s=40&v=4","login":"lukeyeager"},{"avatar_url":"https://avatars.githubusercontent.com/u/6690627?s=40&v=4","login":"jithinjosepkl"}]},{"full_name":"","description":"CUDA Kernel Benchmarking Library","currentPeriodStars":3,"language":"Cuda","languageColor":"#3A4E3A","stargazers_count":543,"forks_count":0,"owner":{"avatar_url":"https://avatars.githubusercontent.com/u/58744?s=40&v=4","login":"alliepiper"},"buildBy":[{"avatar_url":"https://avatars.githubusercontent.com/u/58744?s=40&v=4","login":"alliepiper"},{"avatar_url":"https://avatars.githubusercontent.com/u/9890394?s=40&v=4","login":"gevtushenko"},{"avatar_url":"https://avatars.githubusercontent.com/u/215756?s=40&v=4","login":"robertmaynard"},{"avatar_url":"https://avatars.githubusercontent.com/u/12716979?s=40&v=4","login":"PointKernel"},{"avatar_url":"https://avatars.githubusercontent.com/u/1538165?s=40&v=4","login":"vyasr"}]},{"full_name":"","description":"A massively parallel, optimal functional runtime in Rust","currentPeriodStars":24,"language":"Cuda","languageColor":"#3A4E3A","stargazers_count":10606,"forks_count":0,"owner":{"avatar_url":"https://avatars.githubusercontent.com/u/13090166?s=40&v=4","login":"VictorTaelin"},"buildBy":[{"avatar_url":"https://avatars.githubusercontent.com/u/13090166?s=40&v=4","login":"VictorTaelin"},{"avatar_url":"https://avatars.githubusercontent.com/u/5505315?s=40&v=4","login":"enricozb"},{"avatar_url":"https://avatars.githubusercontent.com/u/53550620?s=40&v=4","login":"kings177"},{"avatar_url":"https://avatars.githubusercontent.com/u/30930225?s=40&v=4","login":"edusporto"},{"avatar_url":"https://avatars.githubusercontent.com/u/44031566?s=40&v=4","login":"tjjfvi"}]},{"full_name":"","description":"CUDA Library Samples","currentPeriodStars":14,"language":"Cuda","languageColor":"#3A4E3A","stargazers_count":1708,"forks_count":0,"owner":{"avatar_url":"https://avatars.githubusercontent.com/u/50021634?s=40&v=4","login":"mnicely"},"buildBy":[{"avatar_url":"https://avatars.githubusercontent.com/u/50021634?s=40&v=4","login":"mnicely"},{"avatar_url":"https://avatars.githubusercontent.com/u/50413820?s=40&v=4","login":"fbusato"},{"avatar_url":"https://avatars.githubusercontent.com/u/20576829?s=40&v=4","login":"almogsegal"},{"avatar_url":"https://avatars.githubusercontent.com/u/5178240?s=40&v=4","login":"springer13"},{"avatar_url":"https://avatars.githubusercontent.com/u/1907101?s=40&v=4","login":"mrogowski"}]},{"full_name":"","description":"RAFT contains fundamental widely-used algorithms and primitives for machine learning and information retrieval. The algorithms are CUDA-accelerated and form building blocks for more easily writing high performance applications.","currentPeriodStars":5,"language":"Cuda","languageColor":"#3A4E3A","stargazers_count":814,"forks_count":0,"owner":{"avatar_url":"https://avatars.githubusercontent.com/u/1242464?s=40&v=4","login":"cjnolet"},"buildBy":[{"avatar_url":"https://avatars.githubusercontent.com/u/1242464?s=40&v=4","login":"cjnolet"},{"avatar_url":"https://avatars.githubusercontent.com/u/38199262?s=40&v=4","login":"GPUtester"},{"avatar_url":"https://avatars.githubusercontent.com/u/37386037?s=40&v=4","login":"aschaffer"},{"avatar_url":"https://avatars.githubusercontent.com/u/9253178?s=40&v=4","login":"achirkin"},{"avatar_url":"https://avatars.githubusercontent.com/u/14876585?s=40&v=4","login":"divyegala"}]},{"full_name":"","description":"cuGraph - RAPIDS Graph Analytics Library","currentPeriodStars":8,"language":"Cuda","languageColor":"#3A4E3A","stargazers_count":1825,"forks_count":0,"owner":{"avatar_url":"https://avatars.githubusercontent.com/u/34135411?s=40&v=4","login":"BradReesWork"},"buildBy":[{"avatar_url":"https://avatars.githubusercontent.com/u/34135411?s=40&v=4","login":"BradReesWork"},{"avatar_url":"https://avatars.githubusercontent.com/u/45606510?s=40&v=4","login":"afender"},{"avatar_url":"https://avatars.githubusercontent.com/u/45364586?s=40&v=4","login":"ChuckHastings"},{"avatar_url":"https://avatars.githubusercontent.com/u/45857425?s=40&v=4","login":"seunghwak"},{"avatar_url":"https://avatars.githubusercontent.com/u/41401566?s=40&v=4","login":"Iroy30"}]},{"full_name":"","description":"A throughput-oriented high-performance serving framework for LLMs","currentPeriodStars":10,"language":"Cuda","languageColor":"#3A4E3A","stargazers_count":691,"forks_count":0,"owner":{"avatar_url":"https://avatars.githubusercontent.com/u/54904336?s=40&v=4","login":"serendipity-zk"},"buildBy":[{"avatar_url":"https://avatars.githubusercontent.com/u/54904336?s=40&v=4","login":"serendipity-zk"},{"avatar_url":"https://avatars.githubusercontent.com/u/658484?s=40&v=4","login":"kasikci"},{"avatar_url":"https://avatars.githubusercontent.com/u/65443542?s=40&v=4","login":"ddxxdd-code"},{"avatar_url":"https://avatars.githubusercontent.com/u/74357408?s=40&v=4","login":"happierpig"},{"avatar_url":"https://avatars.githubusercontent.com/u/124498441?s=40&v=4","login":"maryyufei21"}]},{"full_name":"","description":"[ARCHIVED] Cooperative primitives for CUDA C++. See https://github.com/NVIDIA/cccl","currentPeriodStars":1,"language":"Cuda","languageColor":"#3A4E3A","stargazers_count":1689,"forks_count":0,"owner":{"avatar_url":"https://avatars.githubusercontent.com/u/9890394?s=40&v=4","login":"gevtushenko"},"buildBy":[{"avatar_url":"https://avatars.githubusercontent.com/u/9890394?s=40&v=4","login":"gevtushenko"},{"avatar_url":"https://avatars.githubusercontent.com/u/58744?s=40&v=4","login":"alliepiper"},{"avatar_url":"https://avatars.githubusercontent.com/u/1476032?s=40&v=4","login":"dumerrill"},{"avatar_url":"https://avatars.githubusercontent.com/u/398194?s=40&v=4","login":"brycelelbach"},{"avatar_url":"https://avatars.githubusercontent.com/u/3958403?s=40&v=4","login":"elstehle"}]},{"full_name":"","description":"Causal depthwise conv1d in CUDA, with a PyTorch interface","currentPeriodStars":9,"language":"Cuda","languageColor":"#3A4E3A","stargazers_count":374,"forks_count":0,"owner":{"avatar_url":"https://avatars.githubusercontent.com/u/5616128?s=40&v=4","login":"tridao"},"buildBy":[{"avatar_url":"https://avatars.githubusercontent.com/u/5616128?s=40&v=4","login":"tridao"},{"avatar_url":"https://avatars.githubusercontent.com/u/164261418?s=40&v=4","login":"ajassani"},{"avatar_url":"https://avatars.githubusercontent.com/u/22727137?s=40&v=4","login":"johnnynunez"},{"avatar_url":"https://avatars.githubusercontent.com/u/158011354?s=40&v=4","login":"amoskvic"},{"avatar_url":"https://avatars.githubusercontent.com/u/1236979?s=40&v=4","login":"tlrmchlsmth"}]},{"full_name":"","description":"This is a series of GPU optimization topics. Here we will introduce how to optimize the CUDA kernel in detail. I will introduce several basic kernel optimizations, including: elementwise, reduce, sgemv, sgemm, etc. The performance of these kernels is basically at or near the theoretical limit.","currentPeriodStars":10,"language":"Cuda","languageColor":"#3A4E3A","stargazers_count":885,"forks_count":0,"owner":{"avatar_url":"https://avatars.githubusercontent.com/u/85323580?s=40&v=4","login":"Liu-xiandong"},"buildBy":[{"avatar_url":"https://avatars.githubusercontent.com/u/85323580?s=40&v=4","login":"Liu-xiandong"},{"avatar_url":"https://avatars.githubusercontent.com/u/63796752?s=40&v=4","login":"ZhangGe6"}]},{"full_name":"","description":"","currentPeriodStars":0,"stargazers_count":0,"forks_count":0,"owner":{},"buildBy":[]},{"full_name":"","description":"[MICRO'23, MLSys'22] TorchSparse: Efficient Training and Inference Framework for Sparse Convolution on GPUs.","currentPeriodStars":3,"language":"Cuda","languageColor":"#3A4E3A","stargazers_count":1252,"forks_count":0,"owner":{"avatar_url":"https://avatars.githubusercontent.com/u/30133450?s=40&v=4","login":"kentang-mit"},"buildBy":[{"avatar_url":"https://avatars.githubusercontent.com/u/30133450?s=40&v=4","login":"kentang-mit"},{"avatar_url":"https://avatars.githubusercontent.com/u/2824685?s=40&v=4","login":"clee-ai"},{"avatar_url":"https://avatars.githubusercontent.com/u/61508922?s=40&v=4","login":"ys-2020"},{"avatar_url":"https://avatars.githubusercontent.com/u/11742991?s=40&v=4","login":"sandeepnmenon"},{"avatar_url":"https://avatars.githubusercontent.com/u/20851944?s=40&v=4","login":"Xiuyu-Li"}]}]}
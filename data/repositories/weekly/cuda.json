{"updateTime":"2025-05-09 02:30:39","data":[{"full_name":"","description":"LLM training in simple, raw C/CUDA","currentPeriodStars":61,"language":"Cuda","languageColor":"#3A4E3A","stargazers_count":26552,"forks_count":0,"owner":{"avatar_url":"https://avatars.githubusercontent.com/u/241138?s=40&v=4","login":"karpathy"},"buildBy":[{"avatar_url":"https://avatars.githubusercontent.com/u/241138?s=40&v=4","login":"karpathy"},{"avatar_url":"https://avatars.githubusercontent.com/u/7938269?s=40&v=4","login":"ngc92"},{"avatar_url":"https://avatars.githubusercontent.com/u/29271842?s=40&v=4","login":"gordicaleksa"},{"avatar_url":"https://avatars.githubusercontent.com/u/7082233?s=40&v=4","login":"ademeure"},{"avatar_url":"https://avatars.githubusercontent.com/u/55313766?s=40&v=4","login":"rosslwheeler"}]},{"full_name":"","description":"This package contains the original 2012 AlexNet code.","currentPeriodStars":32,"language":"Cuda","languageColor":"#3A4E3A","stargazers_count":2604,"forks_count":0,"owner":{"avatar_url":"https://avatars.githubusercontent.com/u/1398239?s=40&v=4","login":"laurentes"},"buildBy":[{"avatar_url":"https://avatars.githubusercontent.com/u/1398239?s=40&v=4","login":"laurentes"},{"avatar_url":"https://avatars.githubusercontent.com/u/36940332?s=40&v=4","login":"chm-tluong"}]},{"full_name":"","description":"","currentPeriodStars":0,"stargazers_count":0,"forks_count":0,"owner":{},"buildBy":[]},{"full_name":"","description":"Quantized Attention achieves speedup of 2-3x and 3-5x compared to FlashAttention and xformers, without lossing end-to-end metrics across language, image, and video models.","currentPeriodStars":41,"language":"Cuda","languageColor":"#3A4E3A","stargazers_count":1469,"forks_count":0,"owner":{"avatar_url":"https://avatars.githubusercontent.com/u/59364182?s=40&v=4","login":"jt-zhang"},"buildBy":[{"avatar_url":"https://avatars.githubusercontent.com/u/59364182?s=40&v=4","login":"jt-zhang"},{"avatar_url":"https://avatars.githubusercontent.com/u/110245937?s=40&v=4","login":"jason-huang03"},{"avatar_url":"https://avatars.githubusercontent.com/u/31974251?s=40&v=4","login":"DefTruth"},{"avatar_url":"https://avatars.githubusercontent.com/u/19153797?s=40&v=4","login":"Panchovix"}]},{"full_name":"","description":"Tile primitives for speedy kernels","currentPeriodStars":19,"language":"Cuda","languageColor":"#3A4E3A","stargazers_count":2328,"forks_count":0,"owner":{"avatar_url":"https://avatars.githubusercontent.com/u/11230781?s=40&v=4","login":"benjaminfspector"},"buildBy":[{"avatar_url":"https://avatars.githubusercontent.com/u/11230781?s=40&v=4","login":"benjaminfspector"},{"avatar_url":"https://avatars.githubusercontent.com/u/48185825?s=40&v=4","login":"Aaryan0404"},{"avatar_url":"https://avatars.githubusercontent.com/u/29069240?s=40&v=4","login":"simran-arora"},{"avatar_url":"https://avatars.githubusercontent.com/u/31910389?s=40&v=4","login":"StuartSul"},{"avatar_url":"https://avatars.githubusercontent.com/u/72822184?s=40&v=4","login":"dylanllim"}]},{"full_name":"","description":"","currentPeriodStars":0,"stargazers_count":0,"forks_count":0,"owner":{},"buildBy":[]},{"full_name":"","description":"RAFT contains fundamental widely-used algorithms and primitives for machine learning and information retrieval. The algorithms are CUDA-accelerated and form building blocks for more easily writing high performance applications.","currentPeriodStars":1,"language":"Cuda","languageColor":"#3A4E3A","stargazers_count":877,"forks_count":0,"owner":{"avatar_url":"https://avatars.githubusercontent.com/u/1242464?s=40&v=4","login":"cjnolet"},"buildBy":[{"avatar_url":"https://avatars.githubusercontent.com/u/1242464?s=40&v=4","login":"cjnolet"},{"avatar_url":"https://avatars.githubusercontent.com/u/38199262?s=40&v=4","login":"GPUtester"},{"avatar_url":"https://avatars.githubusercontent.com/u/37386037?s=40&v=4","login":"aschaffer"},{"avatar_url":"https://avatars.githubusercontent.com/u/14876585?s=40&v=4","login":"divyegala"},{"avatar_url":"https://avatars.githubusercontent.com/u/9253178?s=40&v=4","login":"achirkin"}]},{"full_name":"","description":"Causal depthwise conv1d in CUDA, with a PyTorch interface","currentPeriodStars":6,"language":"Cuda","languageColor":"#3A4E3A","stargazers_count":448,"forks_count":0,"owner":{"avatar_url":"https://avatars.githubusercontent.com/u/5616128?s=40&v=4","login":"tridao"},"buildBy":[{"avatar_url":"https://avatars.githubusercontent.com/u/5616128?s=40&v=4","login":"tridao"},{"avatar_url":"https://avatars.githubusercontent.com/u/164261418?s=40&v=4","login":"ajassani"},{"avatar_url":"https://avatars.githubusercontent.com/u/22727137?s=40&v=4","login":"johnnynunez"},{"avatar_url":"https://avatars.githubusercontent.com/u/158011354?s=40&v=4","login":"amoskvic"},{"avatar_url":"https://avatars.githubusercontent.com/u/1236979?s=40&v=4","login":"tlrmchlsmth"}]},{"full_name":"","description":"FlashInfer: Kernel Library for LLM Serving","currentPeriodStars":37,"language":"Cuda","languageColor":"#3A4E3A","stargazers_count":2803,"forks_count":0,"owner":{"avatar_url":"https://avatars.githubusercontent.com/u/11773619?s=40&v=4","login":"yzh119"},"buildBy":[{"avatar_url":"https://avatars.githubusercontent.com/u/11773619?s=40&v=4","login":"yzh119"},{"avatar_url":"https://avatars.githubusercontent.com/u/2470081?s=40&v=4","login":"abcdabcd987"},{"avatar_url":"https://avatars.githubusercontent.com/u/46627482?s=40&v=4","login":"zhyncs"},{"avatar_url":"https://avatars.githubusercontent.com/u/45167100?s=40&v=4","login":"MasterJH5574"},{"avatar_url":"https://avatars.githubusercontent.com/u/961615?s=40&v=4","login":"nandor"}]}]}
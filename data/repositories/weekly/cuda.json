{"updateTime":"2023-01-12 02:25:15","data":[{"full_name":"NVlabs/instant-ngp","description":"Instant neural graphics primitives: lightning fast NeRF and more","currentPeriodStars":146,"language":"Cuda","languageColor":"#3A4E3A","stargazers_count":10723,"forks_count":1277,"owner":{"avatar_url":"https://avatars.githubusercontent.com/u/4923655?s=40&v=4","login":"Tom94"},"buildBy":[{"avatar_url":"https://avatars.githubusercontent.com/u/4923655?s=40&v=4","login":"Tom94"},{"avatar_url":"https://avatars.githubusercontent.com/u/7601391?s=40&v=4","login":"FlorisE"},{"avatar_url":"https://avatars.githubusercontent.com/u/29726242?s=40&v=4","login":"jc211"},{"avatar_url":"https://avatars.githubusercontent.com/u/3280839?s=40&v=4","login":"JamesPerlman"},{"avatar_url":"https://avatars.githubusercontent.com/u/22482773?s=40&v=4","login":"koktavy"}]},{"full_name":"NVIDIA/TransformerEngine","description":"A library for accelerating Transformer models on NVIDIA GPUs, including using 8-bit floating point (FP8) precision on Hopper GPUs, to provide better performance with lower memory utilization in both training and inference.","currentPeriodStars":9,"language":"Cuda","languageColor":"#3A4E3A","stargazers_count":350,"forks_count":36,"owner":{"avatar_url":"https://avatars.githubusercontent.com/u/8398980?s=40&v=4","login":"ptrendx"},"buildBy":[{"avatar_url":"https://avatars.githubusercontent.com/u/8398980?s=40&v=4","login":"ptrendx"},{"avatar_url":"https://avatars.githubusercontent.com/u/36168853?s=40&v=4","login":"ksivaman"},{"avatar_url":"https://avatars.githubusercontent.com/u/4406448?s=40&v=4","login":"timmoon10"},{"avatar_url":"https://avatars.githubusercontent.com/u/14275056?s=40&v=4","login":"zlsh80826"},{"avatar_url":"https://avatars.githubusercontent.com/u/883319?s=40&v=4","login":"seanprime7"}]},{"full_name":"NVIDIA/cub","description":"Cooperative primitives for CUDA C++.","currentPeriodStars":4,"language":"Cuda","languageColor":"#3A4E3A","stargazers_count":1344,"forks_count":415,"owner":{"avatar_url":"https://avatars.githubusercontent.com/u/58744?s=40&v=4","login":"allisonvacanti"},"buildBy":[{"avatar_url":"https://avatars.githubusercontent.com/u/58744?s=40&v=4","login":"allisonvacanti"},{"avatar_url":"https://avatars.githubusercontent.com/u/9890394?s=40&v=4","login":"senior-zero"},{"avatar_url":"https://avatars.githubusercontent.com/u/1476032?s=40&v=4","login":"dumerrill"},{"avatar_url":"https://avatars.githubusercontent.com/u/398194?s=40&v=4","login":"brycelelbach"},{"avatar_url":"https://avatars.githubusercontent.com/u/3958403?s=40&v=4","login":"elstehle"}]},{"full_name":"Liu-xiandong/How_to_optimize_in_GPU","description":"This is a series of GPU optimization topics. Here we will introduce how to optimize the CUDA kernel in detail. I will introduce several basic kernel optimizations, including: elementwise, reduce, sgemv, sgemm, etc. The performance of these kernels is basically at or near the theoretical limit.","currentPeriodStars":10,"language":"Cuda","languageColor":"#3A4E3A","stargazers_count":269,"forks_count":48,"owner":{"avatar_url":"https://avatars.githubusercontent.com/u/85323580?s=40&v=4","login":"Liu-xiandong"},"buildBy":[{"avatar_url":"https://avatars.githubusercontent.com/u/85323580?s=40&v=4","login":"Liu-xiandong"},{"avatar_url":"https://avatars.githubusercontent.com/u/63796752?s=40&v=4","login":"ZhangGe6"}]},{"full_name":"leoxiaobin/deep-high-resolution-net.pytorch","description":"The project is an official implementation of our CVPR2019 paper \"Deep High-Resolution Representation Learning for Human Pose Estimation\"","currentPeriodStars":4,"language":"Cuda","languageColor":"#3A4E3A","stargazers_count":3948,"forks_count":885,"owner":{"avatar_url":"https://avatars.githubusercontent.com/u/5362509?s=40&v=4","login":"leoxiaobin"},"buildBy":[{"avatar_url":"https://avatars.githubusercontent.com/u/5362509?s=40&v=4","login":"leoxiaobin"},{"avatar_url":"https://avatars.githubusercontent.com/u/17076122?s=40&v=4","login":"welleast"},{"avatar_url":"https://avatars.githubusercontent.com/u/44516327?s=40&v=4","login":"CrystalSixone"},{"avatar_url":"https://avatars.githubusercontent.com/u/1326899?s=40&v=4","login":"alex9311"},{"avatar_url":"https://avatars.githubusercontent.com/u/2300329?s=40&v=4","login":"gachiemchiep"}]},{"full_name":"openai/blocksparse","description":"Efficient GPU kernels for block-sparse matrix multiplication and convolution","currentPeriodStars":0,"language":"Cuda","languageColor":"#3A4E3A","stargazers_count":878,"forks_count":168,"owner":{"avatar_url":"https://avatars.githubusercontent.com/u/9326960?s=40&v=4","login":"scott-gray"},"buildBy":[{"avatar_url":"https://avatars.githubusercontent.com/u/9326960?s=40&v=4","login":"scott-gray"},{"avatar_url":"https://avatars.githubusercontent.com/u/369017?s=40&v=4","login":"dchichkov"},{"avatar_url":"https://avatars.githubusercontent.com/u/8098?s=40&v=4","login":"jonasschneider"},{"avatar_url":"https://avatars.githubusercontent.com/u/440336?s=40&v=4","login":"christopherhesse"},{"avatar_url":"https://avatars.githubusercontent.com/u/3162580?s=40&v=4","login":"rewonc"}]},{"full_name":"Tony-Tan/CUDA_Freshman","description":"","currentPeriodStars":0,"stargazers_count":0,"forks_count":0,"owner":{},"buildBy":[]}]}
{"updateTime":"2024-05-28 02:21:22","data":[{"full_name":"","description":"A massively parallel, optimal functional runtime in Rust","currentPeriodStars":1110,"language":"Cuda","languageColor":"#3A4E3A","stargazers_count":9937,"forks_count":0,"owner":{"avatar_url":"https://avatars.githubusercontent.com/u/13090166?s=40&v=4","login":"VictorTaelin"},"buildBy":[{"avatar_url":"https://avatars.githubusercontent.com/u/13090166?s=40&v=4","login":"VictorTaelin"},{"avatar_url":"https://avatars.githubusercontent.com/u/53550620?s=40&v=4","login":"kings177"},{"avatar_url":"https://avatars.githubusercontent.com/u/5505315?s=40&v=4","login":"enricozb"},{"avatar_url":"https://avatars.githubusercontent.com/u/44031566?s=40&v=4","login":"tjjfvi"},{"avatar_url":"https://avatars.githubusercontent.com/u/4893601?s=40&v=4","login":"developedby"}]},{"full_name":"","description":"CUDA Library Samples","currentPeriodStars":55,"language":"Cuda","languageColor":"#3A4E3A","stargazers_count":1318,"forks_count":0,"owner":{"avatar_url":"https://avatars.githubusercontent.com/u/50021634?s=40&v=4","login":"mnicely"},"buildBy":[{"avatar_url":"https://avatars.githubusercontent.com/u/50021634?s=40&v=4","login":"mnicely"},{"avatar_url":"https://avatars.githubusercontent.com/u/50413820?s=40&v=4","login":"fbusato"},{"avatar_url":"https://avatars.githubusercontent.com/u/5178240?s=40&v=4","login":"springer13"},{"avatar_url":"https://avatars.githubusercontent.com/u/20576829?s=40&v=4","login":"almogsegal"},{"avatar_url":"https://avatars.githubusercontent.com/u/1217114?s=40&v=4","login":"llukas"}]},{"full_name":"","description":"üéâCUDA Á¨îËÆ∞ / Â§ßÊ®°ÂûãÊâãÊíïCUDA / C++Á¨îËÆ∞ÔºåÊõ¥Êñ∞ÈöèÁºò: flash_attn„ÄÅsgemm„ÄÅsgemv„ÄÅwarp reduce„ÄÅblock reduce„ÄÅdot product„ÄÅelementwise„ÄÅsoftmax„ÄÅlayernorm„ÄÅrmsnorm„ÄÅhist etc.","currentPeriodStars":29,"language":"Cuda","languageColor":"#3A4E3A","stargazers_count":614,"forks_count":0,"owner":{"avatar_url":"https://avatars.githubusercontent.com/u/31974251?s=40&v=4","login":"DefTruth"},"buildBy":[{"avatar_url":"https://avatars.githubusercontent.com/u/31974251?s=40&v=4","login":"DefTruth"}]},{"full_name":"","description":"Fast CUDA matrix multiplication from scratch","currentPeriodStars":13,"language":"Cuda","languageColor":"#3A4E3A","stargazers_count":298,"forks_count":0,"owner":{"avatar_url":"https://avatars.githubusercontent.com/u/14908678?s=40&v=4","login":"siboehm"},"buildBy":[{"avatar_url":"https://avatars.githubusercontent.com/u/14908678?s=40&v=4","login":"siboehm"}]},{"full_name":"","description":"CUDA Kernel Benchmarking Library","currentPeriodStars":4,"language":"Cuda","languageColor":"#3A4E3A","stargazers_count":427,"forks_count":0,"owner":{"avatar_url":"https://avatars.githubusercontent.com/u/58744?s=40&v=4","login":"alliepiper"},"buildBy":[{"avatar_url":"https://avatars.githubusercontent.com/u/58744?s=40&v=4","login":"alliepiper"},{"avatar_url":"https://avatars.githubusercontent.com/u/9890394?s=40&v=4","login":"gevtushenko"},{"avatar_url":"https://avatars.githubusercontent.com/u/215756?s=40&v=4","login":"robertmaynard"},{"avatar_url":"https://avatars.githubusercontent.com/u/12716979?s=40&v=4","login":"PointKernel"},{"avatar_url":"https://avatars.githubusercontent.com/u/1538165?s=40&v=4","login":"vyasr"}]},{"full_name":"","description":"[MICRO'23, MLSys'22] TorchSparse: Efficient Training and Inference Framework for Sparse Convolution on GPUs.","currentPeriodStars":7,"language":"Cuda","languageColor":"#3A4E3A","stargazers_count":1129,"forks_count":0,"owner":{"avatar_url":"https://avatars.githubusercontent.com/u/30133450?s=40&v=4","login":"kentang-mit"},"buildBy":[{"avatar_url":"https://avatars.githubusercontent.com/u/30133450?s=40&v=4","login":"kentang-mit"},{"avatar_url":"https://avatars.githubusercontent.com/u/2824685?s=40&v=4","login":"CCInc"},{"avatar_url":"https://avatars.githubusercontent.com/u/11742991?s=40&v=4","login":"sandeepnmenon"},{"avatar_url":"https://avatars.githubusercontent.com/u/61508922?s=40&v=4","login":"ys-2020"},{"avatar_url":"https://avatars.githubusercontent.com/u/20851944?s=40&v=4","login":"Xiuyu-Li"}]},{"full_name":"","description":"Causal depthwise conv1d in CUDA, with a PyTorch interface","currentPeriodStars":5,"language":"Cuda","languageColor":"#3A4E3A","stargazers_count":191,"forks_count":0,"owner":{"avatar_url":"https://avatars.githubusercontent.com/u/5616128?s=40&v=4","login":"tridao"},"buildBy":[{"avatar_url":"https://avatars.githubusercontent.com/u/5616128?s=40&v=4","login":"tridao"},{"avatar_url":"https://avatars.githubusercontent.com/u/9017200?s=40&v=4","login":"havietisov"},{"avatar_url":"https://avatars.githubusercontent.com/u/32878682?s=40&v=4","login":"IamShubhamGupto"},{"avatar_url":"https://avatars.githubusercontent.com/u/44860323?s=40&v=4","login":"Wongboo"}]},{"full_name":"","description":"Sample codes for my CUDA programming book","currentPeriodStars":11,"language":"Cuda","languageColor":"#3A4E3A","stargazers_count":1386,"forks_count":0,"owner":{"avatar_url":"https://avatars.githubusercontent.com/u/24891193?s=40&v=4","login":"brucefan1983"},"buildBy":[{"avatar_url":"https://avatars.githubusercontent.com/u/24891193?s=40&v=4","login":"brucefan1983"},{"avatar_url":"https://avatars.githubusercontent.com/u/36254396?s=40&v=4","login":"YouQixiaowu"},{"avatar_url":"https://avatars.githubusercontent.com/u/19585240?s=40&v=4","login":"tomguluson92"}]},{"full_name":"","description":"FlashInfer: Kernel Library for LLM Serving","currentPeriodStars":19,"language":"Cuda","languageColor":"#3A4E3A","stargazers_count":692,"forks_count":0,"owner":{"avatar_url":"https://avatars.githubusercontent.com/u/11773619?s=40&v=4","login":"yzh119"},"buildBy":[{"avatar_url":"https://avatars.githubusercontent.com/u/11773619?s=40&v=4","login":"yzh119"},{"avatar_url":"https://avatars.githubusercontent.com/u/45167100?s=40&v=4","login":"MasterJH5574"},{"avatar_url":"https://avatars.githubusercontent.com/u/2470081?s=40&v=4","login":"abcdabcd987"},{"avatar_url":"https://avatars.githubusercontent.com/u/22515877?s=40&v=4","login":"junrushao"},{"avatar_url":"https://avatars.githubusercontent.com/u/6694539?s=40&v=4","login":"esmeetu"}]},{"full_name":"","description":"Instant neural graphics primitives: lightning fast NeRF and more","currentPeriodStars":31,"language":"Cuda","languageColor":"#3A4E3A","stargazers_count":15473,"forks_count":0,"owner":{"avatar_url":"https://avatars.githubusercontent.com/u/4923655?s=40&v=4","login":"Tom94"},"buildBy":[{"avatar_url":"https://avatars.githubusercontent.com/u/4923655?s=40&v=4","login":"Tom94"},{"avatar_url":"https://avatars.githubusercontent.com/u/7601391?s=40&v=4","login":"FlorisE"},{"avatar_url":"https://avatars.githubusercontent.com/u/29726242?s=40&v=4","login":"jc211"},{"avatar_url":"https://avatars.githubusercontent.com/u/7057863?s=40&v=4","login":"yenchenlin"},{"avatar_url":"https://avatars.githubusercontent.com/u/3280839?s=40&v=4","login":"JamesPerlman"}]},{"full_name":"","description":"A differentiable rasterizer used in the project \"2D Gaussian Splatting\"","currentPeriodStars":7,"language":"Cuda","languageColor":"#3A4E3A","stargazers_count":59,"forks_count":0,"owner":{"avatar_url":"https://avatars.githubusercontent.com/u/57170935?s=40&v=4","login":"hbb1"},"buildBy":[{"avatar_url":"https://avatars.githubusercontent.com/u/57170935?s=40&v=4","login":"hbb1"}]},{"full_name":"","description":"CUDA accelerated rasterization of gaussian splatting","currentPeriodStars":16,"language":"Cuda","languageColor":"#3A4E3A","stargazers_count":902,"forks_count":0,"owner":{"avatar_url":"https://avatars.githubusercontent.com/u/5694811?s=40&v=4","login":"vye16"},"buildBy":[{"avatar_url":"https://avatars.githubusercontent.com/u/5694811?s=40&v=4","login":"vye16"},{"avatar_url":"https://avatars.githubusercontent.com/u/10151885?s=40&v=4","login":"liruilong940607"},{"avatar_url":"https://avatars.githubusercontent.com/u/30566358?s=40&v=4","login":"maturk"},{"avatar_url":"https://avatars.githubusercontent.com/u/15806475?s=40&v=4","login":"kerrj"},{"avatar_url":"https://avatars.githubusercontent.com/u/102644383?s=40&v=4","login":"Zhuoyang-Pan"}]},{"full_name":"","description":"[ARCHIVED] Cooperative primitives for CUDA C++. See https://github.com/NVIDIA/cccl","currentPeriodStars":2,"language":"Cuda","languageColor":"#3A4E3A","stargazers_count":1653,"forks_count":0,"owner":{"avatar_url":"https://avatars.githubusercontent.com/u/9890394?s=40&v=4","login":"gevtushenko"},"buildBy":[{"avatar_url":"https://avatars.githubusercontent.com/u/9890394?s=40&v=4","login":"gevtushenko"},{"avatar_url":"https://avatars.githubusercontent.com/u/58744?s=40&v=4","login":"alliepiper"},{"avatar_url":"https://avatars.githubusercontent.com/u/1476032?s=40&v=4","login":"dumerrill"},{"avatar_url":"https://avatars.githubusercontent.com/u/398194?s=40&v=4","login":"brycelelbach"},{"avatar_url":"https://avatars.githubusercontent.com/u/3958403?s=40&v=4","login":"elstehle"}]},{"full_name":"","description":"","currentPeriodStars":0,"stargazers_count":0,"forks_count":0,"owner":{},"buildBy":[]},{"full_name":"","description":"flash attention tutorial written in python, triton, cuda, cutlass","currentPeriodStars":11,"language":"Cuda","languageColor":"#3A4E3A","stargazers_count":55,"forks_count":0,"owner":{"avatar_url":"https://avatars.githubusercontent.com/u/49358576?s=40&v=4","login":"66RING"},"buildBy":[{"avatar_url":"https://avatars.githubusercontent.com/u/49358576?s=40&v=4","login":"66RING"}]},{"full_name":"","description":"how to optimize some algorithm in cuda.","currentPeriodStars":16,"language":"Cuda","languageColor":"#3A4E3A","stargazers_count":1048,"forks_count":0,"owner":{"avatar_url":"https://avatars.githubusercontent.com/u/35585791?s=40&v=4","login":"BBuf"},"buildBy":[{"avatar_url":"https://avatars.githubusercontent.com/u/35585791?s=40&v=4","login":"BBuf"},{"avatar_url":"https://avatars.githubusercontent.com/u/67543126?s=40&v=4","login":"peakcrosser7"}]},{"full_name":"","description":"cuGraph - RAPIDS Graph Analytics Library","currentPeriodStars":10,"language":"Cuda","languageColor":"#3A4E3A","stargazers_count":1599,"forks_count":0,"owner":{"avatar_url":"https://avatars.githubusercontent.com/u/34135411?s=40&v=4","login":"BradReesWork"},"buildBy":[{"avatar_url":"https://avatars.githubusercontent.com/u/34135411?s=40&v=4","login":"BradReesWork"},{"avatar_url":"https://avatars.githubusercontent.com/u/45606510?s=40&v=4","login":"afender"},{"avatar_url":"https://avatars.githubusercontent.com/u/45857425?s=40&v=4","login":"seunghwak"},{"avatar_url":"https://avatars.githubusercontent.com/u/45364586?s=40&v=4","login":"ChuckHastings"},{"avatar_url":"https://avatars.githubusercontent.com/u/41401566?s=40&v=4","login":"Iroy30"}]},{"full_name":"","description":"This is a series of GPU optimization topics. Here we will introduce how to optimize the CUDA kernel in detail. I will introduce several basic kernel optimizations, including: elementwise, reduce, sgemv, sgemm, etc. The performance of these kernels is basically at or near the theoretical limit.","currentPeriodStars":6,"language":"Cuda","languageColor":"#3A4E3A","stargazers_count":704,"forks_count":0,"owner":{"avatar_url":"https://avatars.githubusercontent.com/u/85323580?s=40&v=4","login":"Liu-xiandong"},"buildBy":[{"avatar_url":"https://avatars.githubusercontent.com/u/85323580?s=40&v=4","login":"Liu-xiandong"},{"avatar_url":"https://avatars.githubusercontent.com/u/63796752?s=40&v=4","login":"ZhangGe6"}]}]}